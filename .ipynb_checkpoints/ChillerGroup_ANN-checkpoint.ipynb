{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2577f25-5881-450b-a364-f937186ca46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9316, 16)\n",
      "(9006, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>chillersFMU.mCenChi</th>\n",
       "      <th>chillersFMU.mAbsChi</th>\n",
       "      <th>chillersFMU.TWetBul</th>\n",
       "      <th>chillersFMU.Qchp</th>\n",
       "      <th>chillersFMU.mChiWat</th>\n",
       "      <th>chillersFMU.pChi</th>\n",
       "      <th>chillersFMU.pFan</th>\n",
       "      <th>chillersFMU.TchiSup</th>\n",
       "      <th>chillersFMU.TchiAbsSup</th>\n",
       "      <th>chillersFMU.QchiAbs</th>\n",
       "      <th>chillersFMU.pPumAbs</th>\n",
       "      <th>chillersFMU.pFanAbs</th>\n",
       "      <th>chillersFMU.absChiOn</th>\n",
       "      <th>chillersFMU.yVal</th>\n",
       "      <th>chillersFMU.pPum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.37</td>\n",
       "      <td>1000000.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>293.15</td>\n",
       "      <td>293.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.37</td>\n",
       "      <td>1000456.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>293.15</td>\n",
       "      <td>293.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.23</td>\n",
       "      <td>1000913.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>293.15</td>\n",
       "      <td>293.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262.86</td>\n",
       "      <td>1001369.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>293.15</td>\n",
       "      <td>293.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.82</td>\n",
       "      <td>1001826.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>293.15</td>\n",
       "      <td>293.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  chillersFMU.mCenChi  chillersFMU.mAbsChi  chillersFMU.TWetBul  \\\n",
       "0      0.0                  0.0                  0.0               264.37   \n",
       "1   3600.0                  0.0                  0.0               264.37   \n",
       "2   7200.0                  0.0                  0.0               263.23   \n",
       "3  10800.0                  0.0                  0.0               262.86   \n",
       "4  14400.0                  0.0                  0.0               261.82   \n",
       "\n",
       "   chillersFMU.Qchp  chillersFMU.mChiWat  chillersFMU.pChi  chillersFMU.pFan  \\\n",
       "0        1000000.00                  0.0               0.0            5000.0   \n",
       "1        1000456.60                  0.0               0.0            5000.0   \n",
       "2        1000913.25                  0.0               0.0            5000.0   \n",
       "3        1001369.90                  0.0               0.0            5000.0   \n",
       "4        1001826.50                  0.0               0.0            5000.0   \n",
       "\n",
       "   chillersFMU.TchiSup  chillersFMU.TchiAbsSup  chillersFMU.QchiAbs  \\\n",
       "0               293.15                  293.15                  0.0   \n",
       "1               293.15                  293.15                  0.0   \n",
       "2               293.15                  293.15                  0.0   \n",
       "3               293.15                  293.15                  0.0   \n",
       "4               293.15                  293.15                  0.0   \n",
       "\n",
       "   chillersFMU.pPumAbs  chillersFMU.pFanAbs  chillersFMU.absChiOn  \\\n",
       "0                  0.0                  0.0                     0   \n",
       "1                  0.0                  0.0                     0   \n",
       "2                  0.0                  0.0                     0   \n",
       "3                  0.0                  0.0                     0   \n",
       "4                  0.0                  0.0                     0   \n",
       "\n",
       "   chillersFMU.yVal  chillersFMU.pPum  \n",
       "0               0.0               0.0  \n",
       "1               0.0               0.0  \n",
       "2               0.0               0.0  \n",
       "3               0.0               0.0  \n",
       "4               0.0               0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ANN chiller group model\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('chillerGroupResults.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.shape)\n",
    "data.drop_duplicates(subset = ['Time'], inplace = True)\n",
    "print(data.shape)\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004e6200",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>chillersFMU.mCenChi</th>\n",
       "      <th>chillersFMU.mAbsChi</th>\n",
       "      <th>chillersFMU.TWetBul</th>\n",
       "      <th>chillersFMU.Qchp</th>\n",
       "      <th>chillersFMU.mChiWat</th>\n",
       "      <th>chillersFMU.pChi</th>\n",
       "      <th>chillersFMU.pFan</th>\n",
       "      <th>chillersFMU.TchiSup</th>\n",
       "      <th>chillersFMU.TchiAbsSup</th>\n",
       "      <th>chillersFMU.QchiAbs</th>\n",
       "      <th>chillersFMU.pPumAbs</th>\n",
       "      <th>chillersFMU.pFanAbs</th>\n",
       "      <th>chillersFMU.absChiOn</th>\n",
       "      <th>chillersFMU.yVal</th>\n",
       "      <th>chillersFMU.pPum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.37</td>\n",
       "      <td>1000000.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>287.375</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.37</td>\n",
       "      <td>1000456.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>287.375</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.23</td>\n",
       "      <td>1000913.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>287.375</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262.86</td>\n",
       "      <td>1001369.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>287.375</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.82</td>\n",
       "      <td>1001826.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>287.375</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  chillersFMU.mCenChi  chillersFMU.mAbsChi  chillersFMU.TWetBul  \\\n",
       "0      0.0                  0.0                  0.0               264.37   \n",
       "1   3600.0                  0.0                  0.0               264.37   \n",
       "2   7200.0                  0.0                  0.0               263.23   \n",
       "3  10800.0                  0.0                  0.0               262.86   \n",
       "4  14400.0                  0.0                  0.0               261.82   \n",
       "\n",
       "   chillersFMU.Qchp  chillersFMU.mChiWat  chillersFMU.pChi  chillersFMU.pFan  \\\n",
       "0        1000000.00                  0.0               0.0          559.5375   \n",
       "1        1000456.60                  0.0               0.0          559.5375   \n",
       "2        1000913.25                  0.0               0.0          559.5375   \n",
       "3        1001369.90                  0.0               0.0          559.5375   \n",
       "4        1001826.50                  0.0               0.0          559.5375   \n",
       "\n",
       "   chillersFMU.TchiSup  chillersFMU.TchiAbsSup  chillersFMU.QchiAbs  \\\n",
       "0              287.375                  281.15                  0.0   \n",
       "1              287.375                  281.15                  0.0   \n",
       "2              287.375                  281.15                  0.0   \n",
       "3              287.375                  281.15                  0.0   \n",
       "4              287.375                  281.15                  0.0   \n",
       "\n",
       "   chillersFMU.pPumAbs  chillersFMU.pFanAbs  chillersFMU.absChiOn  \\\n",
       "0                  0.0                  0.0                     0   \n",
       "1                  0.0                  0.0                     0   \n",
       "2                  0.0                  0.0                     0   \n",
       "3                  0.0                  0.0                     0   \n",
       "4                  0.0                  0.0                     0   \n",
       "\n",
       "   chillersFMU.yVal  chillersFMU.pPum  \n",
       "0               0.0               0.0  \n",
       "1               0.0               0.0  \n",
       "2               0.0               0.0  \n",
       "3               0.0               0.0  \n",
       "4               0.0               0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier clipping\n",
    "inputs = ['chillersFMU.TWetBul', 'chillersFMU.mChiWat', 'chillersFMU.Qchp', 'chillersFMU.absChiOn'] ##States and actions\n",
    "outputs = ['chillersFMU.pPumAbs', 'chillersFMU.pFanAbs', 'chillersFMU.pPum', 'chillersFMU.pFan', \n",
    "           'chillersFMU.yVal', 'chillersFMU.TchiAbsSup', 'chillersFMU.TchiSup', 'chillersFMU.pChi', \n",
    "           'chillersFMU.QchiAbs','chillersFMU.mAbsChi','chillersFMU.mCenChi' ] \n",
    "\n",
    "\n",
    "# 1st output, 2nd input predicts 2nd output\n",
    "# 2nd output, 3rd input predicts 3rd output\n",
    "\n",
    "columns = inputs + outputs\n",
    "\n",
    "mean = data[columns].mean()\n",
    "q1 = data[columns].quantile(0.25)\n",
    "q3 = data[columns].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "data[columns] = data[columns].clip(q1 - 1.5*iqr, q3 + 1.5*iqr, axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf9c67-81ff-4953-bb4a-b10ecd21736e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ae0903-efb6-47e1-b3ca-07b92ce1f813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define inputs and outputs\n",
    "##ANN outputs\n",
    "\n",
    "# Create input and output datasets\n",
    "X = pd.concat([data[inputs].iloc[1:].reset_index(drop = True), data[outputs].iloc[:-1]], axis=1)\n",
    "y = data[outputs].iloc[1:]\n",
    "\n",
    "X.index = data.Time[1:]\n",
    "y.index = data.Time[1:]\n",
    "# X = X.iloc[1:]\n",
    "# X = pd.concat([X, y.iloc[:-1]], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c782d83a-2703-40de-91a2-e78795ad9688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chillersFMU.TWetBul</th>\n",
       "      <th>chillersFMU.mChiWat</th>\n",
       "      <th>chillersFMU.Qchp</th>\n",
       "      <th>chillersFMU.absChiOn</th>\n",
       "      <th>chillersFMU.pPumAbs</th>\n",
       "      <th>chillersFMU.pFanAbs</th>\n",
       "      <th>chillersFMU.pPum</th>\n",
       "      <th>chillersFMU.pFan</th>\n",
       "      <th>chillersFMU.yVal</th>\n",
       "      <th>chillersFMU.TchiAbsSup</th>\n",
       "      <th>chillersFMU.TchiSup</th>\n",
       "      <th>chillersFMU.pChi</th>\n",
       "      <th>chillersFMU.QchiAbs</th>\n",
       "      <th>chillersFMU.mAbsChi</th>\n",
       "      <th>chillersFMU.mCenChi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600.0</th>\n",
       "      <td>264.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000456.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7200.0</th>\n",
       "      <td>263.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000913.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800.0</th>\n",
       "      <td>262.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001369.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14400.0</th>\n",
       "      <td>261.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001826.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000.0</th>\n",
       "      <td>262.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1002283.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         chillersFMU.TWetBul  chillersFMU.mChiWat  chillersFMU.Qchp  \\\n",
       "Time                                                                  \n",
       "3600.0                264.37                  0.0        1000456.60   \n",
       "7200.0                263.23                  0.0        1000913.25   \n",
       "10800.0               262.86                  0.0        1001369.90   \n",
       "14400.0               261.82                  0.0        1001826.50   \n",
       "18000.0               262.16                  0.0        1002283.10   \n",
       "\n",
       "         chillersFMU.absChiOn  chillersFMU.pPumAbs  chillersFMU.pFanAbs  \\\n",
       "Time                                                                      \n",
       "3600.0                      0                  0.0                  0.0   \n",
       "7200.0                      0                  0.0                  0.0   \n",
       "10800.0                     0                  0.0                  0.0   \n",
       "14400.0                     0                  0.0                  0.0   \n",
       "18000.0                     0                  0.0                  0.0   \n",
       "\n",
       "         chillersFMU.pPum  chillersFMU.pFan  chillersFMU.yVal  \\\n",
       "Time                                                            \n",
       "3600.0                0.0          559.5375               0.0   \n",
       "7200.0                0.0          559.5375               0.0   \n",
       "10800.0               0.0          559.5375               0.0   \n",
       "14400.0               0.0          559.5375               0.0   \n",
       "18000.0               0.0          559.5375               0.0   \n",
       "\n",
       "         chillersFMU.TchiAbsSup  chillersFMU.TchiSup  chillersFMU.pChi  \\\n",
       "Time                                                                     \n",
       "3600.0                   281.15              287.375               0.0   \n",
       "7200.0                   281.15              287.375               0.0   \n",
       "10800.0                  281.15              287.375               0.0   \n",
       "14400.0                  281.15              287.375               0.0   \n",
       "18000.0                  281.15              287.375               0.0   \n",
       "\n",
       "         chillersFMU.QchiAbs  chillersFMU.mAbsChi  chillersFMU.mCenChi  \n",
       "Time                                                                    \n",
       "3600.0                   0.0                  0.0                  0.0  \n",
       "7200.0                   0.0                  0.0                  0.0  \n",
       "10800.0                  0.0                  0.0                  0.0  \n",
       "14400.0                  0.0                  0.0                  0.0  \n",
       "18000.0                  0.0                  0.0                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f15981-5e24-4ff5-ac0e-6c5291e6f281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chillersFMU.pPumAbs</th>\n",
       "      <th>chillersFMU.pFanAbs</th>\n",
       "      <th>chillersFMU.pPum</th>\n",
       "      <th>chillersFMU.pFan</th>\n",
       "      <th>chillersFMU.yVal</th>\n",
       "      <th>chillersFMU.TchiAbsSup</th>\n",
       "      <th>chillersFMU.TchiSup</th>\n",
       "      <th>chillersFMU.pChi</th>\n",
       "      <th>chillersFMU.QchiAbs</th>\n",
       "      <th>chillersFMU.mAbsChi</th>\n",
       "      <th>chillersFMU.mCenChi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7200.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14400.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.15</td>\n",
       "      <td>287.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         chillersFMU.pPumAbs  chillersFMU.pFanAbs  chillersFMU.pPum  \\\n",
       "Time                                                                  \n",
       "3600.0                   0.0                  0.0               0.0   \n",
       "7200.0                   0.0                  0.0               0.0   \n",
       "10800.0                  0.0                  0.0               0.0   \n",
       "14400.0                  0.0                  0.0               0.0   \n",
       "18000.0                  0.0                  0.0               0.0   \n",
       "\n",
       "         chillersFMU.pFan  chillersFMU.yVal  chillersFMU.TchiAbsSup  \\\n",
       "Time                                                                  \n",
       "3600.0           559.5375               0.0                  281.15   \n",
       "7200.0           559.5375               0.0                  281.15   \n",
       "10800.0          559.5375               0.0                  281.15   \n",
       "14400.0          559.5375               0.0                  281.15   \n",
       "18000.0          559.5375               0.0                  281.15   \n",
       "\n",
       "         chillersFMU.TchiSup  chillersFMU.pChi  chillersFMU.QchiAbs  \\\n",
       "Time                                                                  \n",
       "3600.0               287.375               0.0                  0.0   \n",
       "7200.0               287.375               0.0                  0.0   \n",
       "10800.0              287.375               0.0                  0.0   \n",
       "14400.0              287.375               0.0                  0.0   \n",
       "18000.0              287.375               0.0                  0.0   \n",
       "\n",
       "         chillersFMU.mAbsChi  chillersFMU.mCenChi  \n",
       "Time                                               \n",
       "3600.0                   0.0                  0.0  \n",
       "7200.0                   0.0                  0.0  \n",
       "10800.0                  0.0                  0.0  \n",
       "14400.0                  0.0                  0.0  \n",
       "18000.0                  0.0                  0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e9cea7-01f7-453b-8996-82a36433cd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9005, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd95e1a-7178-4c00-a580-44c563f7d433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9005, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3836f1-d5cf-4ea0-997d-5d7b59e305ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440    5184000.0\n",
       "1441    5187600.0\n",
       "1442    5191200.0\n",
       "1443    5194800.0\n",
       "1444    5198400.0\n",
       "          ...    \n",
       "2161    7761600.0\n",
       "2162    7765200.0\n",
       "2163    7768800.0\n",
       "2164    7772400.0\n",
       "2165    7776000.0\n",
       "Name: Time, Length: 726, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.Series(X.index)\n",
    "index[(index >= 2*30*86400) & (index<=3*30*86400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95ac561-feb0-42fd-adf4-be71c227e269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "month = 30*86400\n",
    "import numpy as np\n",
    "def split_data_20_10(X, y):\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    index = pd.Series(X.index)\n",
    "    for i in range(0, int(X.index[-1])//month):\n",
    "\n",
    "        index_filter = index[(index >= i*30*86400) & (index<=(i+1)*30*86400)]\n",
    "        \n",
    "        X_train.append(X.loc[index_filter[:int(len(index_filter)*0.7)]])\n",
    "        y_train.append(y.loc[index_filter[:int(len(index_filter)*0.7)]])\n",
    "        X_test.append(X.loc[index_filter[int(len(index_filter)*0.7):]])\n",
    "        y_test.append(y.loc[index_filter[int(len(index_filter)*0.7):]])\n",
    "\n",
    "    return np.vstack(X_train), np.vstack(X_test), np.vstack(y_train), np.vstack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2c0795-ac13-4df8-9ddb-fd4f8fec0695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data_20_10(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a1907fe-08c7-4983-a253-dbc9d65982ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = X.iloc[:int(0.8*len(X))], X.iloc[int(0.8*len(X)):], y.iloc[:int(0.8*len(y))], y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "# Normalize the features\n",
    "scaler_X = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler_X.transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(y_train)\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fecde06-6f4e-4008-9024-1141fd414f31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6220, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c901d2-b61a-438b-aad8-2a6dd26e893d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(len(outputs)),  # Output layer with the same number of neurons as target features\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), loss='mean_squared_error', metrics=['mae']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc98db8-4d80-41f7-b27b-6346e4f3d9aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2606 - mae: 0.4020 - val_loss: 0.1494 - val_mae: 0.3008\n",
      "Epoch 2/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1110 - mae: 0.2595 - val_loss: 0.0987 - val_mae: 0.2628\n",
      "Epoch 3/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0813 - mae: 0.2322 - val_loss: 0.0830 - val_mae: 0.2271\n",
      "Epoch 4/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0574 - mae: 0.1898 - val_loss: 0.0626 - val_mae: 0.1926\n",
      "Epoch 5/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1460 - val_loss: 0.0448 - val_mae: 0.1566\n",
      "Epoch 6/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0227 - mae: 0.1118 - val_loss: 0.0386 - val_mae: 0.1408\n",
      "Epoch 7/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mae: 0.0916 - val_loss: 0.0364 - val_mae: 0.1341\n",
      "Epoch 8/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mae: 0.0802 - val_loss: 0.0368 - val_mae: 0.1344\n",
      "Epoch 9/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0151 - mae: 0.0760 - val_loss: 0.0325 - val_mae: 0.1244\n",
      "Epoch 10/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0726 - val_loss: 0.0367 - val_mae: 0.1352\n",
      "Epoch 11/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0734 - val_loss: 0.0324 - val_mae: 0.1253\n",
      "Epoch 12/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0732 - val_loss: 0.0313 - val_mae: 0.1228\n",
      "Epoch 13/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0714 - val_loss: 0.0323 - val_mae: 0.1246\n",
      "Epoch 14/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0706 - val_loss: 0.0287 - val_mae: 0.1183\n",
      "Epoch 15/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0702 - val_loss: 0.0302 - val_mae: 0.1221\n",
      "Epoch 16/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0688 - val_loss: 0.0289 - val_mae: 0.1194\n",
      "Epoch 17/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0690 - val_loss: 0.0257 - val_mae: 0.1135\n",
      "Epoch 18/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0655 - val_loss: 0.0250 - val_mae: 0.1103\n",
      "Epoch 19/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0648 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 20/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0625 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 21/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mae: 0.0598 - val_loss: 0.0192 - val_mae: 0.0966\n",
      "Epoch 22/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - mae: 0.0593 - val_loss: 0.0204 - val_mae: 0.1014\n",
      "Epoch 23/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mae: 0.0561 - val_loss: 0.0179 - val_mae: 0.0955\n",
      "Epoch 24/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0523 - val_loss: 0.0158 - val_mae: 0.0899\n",
      "Epoch 25/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0490 - val_loss: 0.0145 - val_mae: 0.0848\n",
      "Epoch 26/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0481 - val_loss: 0.0130 - val_mae: 0.0801\n",
      "Epoch 27/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - mae: 0.0450 - val_loss: 0.0118 - val_mae: 0.0751\n",
      "Epoch 28/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - mae: 0.0442 - val_loss: 0.0108 - val_mae: 0.0730\n",
      "Epoch 29/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mae: 0.0416 - val_loss: 0.0095 - val_mae: 0.0676\n",
      "Epoch 30/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mae: 0.0406 - val_loss: 0.0089 - val_mae: 0.0659\n",
      "Epoch 31/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0393 - val_loss: 0.0087 - val_mae: 0.0649\n",
      "Epoch 32/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0377 - val_loss: 0.0082 - val_mae: 0.0632\n",
      "Epoch 33/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mae: 0.0372 - val_loss: 0.0074 - val_mae: 0.0588\n",
      "Epoch 34/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0358 - val_loss: 0.0076 - val_mae: 0.0602\n",
      "Epoch 35/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mae: 0.0356 - val_loss: 0.0072 - val_mae: 0.0577\n",
      "Epoch 36/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mae: 0.0347 - val_loss: 0.0069 - val_mae: 0.0551\n",
      "Epoch 37/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - mae: 0.0330 - val_loss: 0.0065 - val_mae: 0.0524\n",
      "Epoch 38/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - mae: 0.0326 - val_loss: 0.0062 - val_mae: 0.0511\n",
      "Epoch 39/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - mae: 0.0325 - val_loss: 0.0059 - val_mae: 0.0487\n",
      "Epoch 40/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mae: 0.0323 - val_loss: 0.0057 - val_mae: 0.0481\n",
      "Epoch 41/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mae: 0.0311 - val_loss: 0.0056 - val_mae: 0.0488\n",
      "Epoch 42/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mae: 0.0313 - val_loss: 0.0051 - val_mae: 0.0444\n",
      "Epoch 43/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - mae: 0.0305 - val_loss: 0.0052 - val_mae: 0.0464\n",
      "Epoch 44/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - mae: 0.0308 - val_loss: 0.0050 - val_mae: 0.0445\n",
      "Epoch 45/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0300 - val_loss: 0.0050 - val_mae: 0.0436\n",
      "Epoch 46/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - mae: 0.0296 - val_loss: 0.0046 - val_mae: 0.0428\n",
      "Epoch 47/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0286 - val_loss: 0.0048 - val_mae: 0.0419\n",
      "Epoch 48/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - mae: 0.0299 - val_loss: 0.0044 - val_mae: 0.0395\n",
      "Epoch 49/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mae: 0.0287 - val_loss: 0.0042 - val_mae: 0.0389\n",
      "Epoch 50/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mae: 0.0287 - val_loss: 0.0045 - val_mae: 0.0413\n",
      "Epoch 51/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0286 - val_loss: 0.0041 - val_mae: 0.0380\n",
      "Epoch 52/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - mae: 0.0283 - val_loss: 0.0041 - val_mae: 0.0371\n",
      "Epoch 53/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0288 - val_loss: 0.0038 - val_mae: 0.0353\n",
      "Epoch 54/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0280 - val_loss: 0.0039 - val_mae: 0.0360\n",
      "Epoch 55/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0275 - val_loss: 0.0037 - val_mae: 0.0333\n",
      "Epoch 56/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0274 - val_loss: 0.0037 - val_mae: 0.0354\n",
      "Epoch 57/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0271 - val_loss: 0.0040 - val_mae: 0.0374\n",
      "Epoch 58/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0275 - val_loss: 0.0038 - val_mae: 0.0339\n",
      "Epoch 59/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0266 - val_loss: 0.0035 - val_mae: 0.0329\n",
      "Epoch 60/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0267 - val_loss: 0.0036 - val_mae: 0.0335\n",
      "Epoch 61/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0269 - val_loss: 0.0036 - val_mae: 0.0332\n",
      "Epoch 62/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0261 - val_loss: 0.0033 - val_mae: 0.0307\n",
      "Epoch 63/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0264 - val_loss: 0.0033 - val_mae: 0.0305\n",
      "Epoch 64/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0263 - val_loss: 0.0032 - val_mae: 0.0299\n",
      "Epoch 65/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0266 - val_loss: 0.0033 - val_mae: 0.0305\n",
      "Epoch 66/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0265 - val_loss: 0.0033 - val_mae: 0.0311\n",
      "Epoch 67/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0255 - val_loss: 0.0031 - val_mae: 0.0288\n",
      "Epoch 68/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0258 - val_loss: 0.0031 - val_mae: 0.0292\n",
      "Epoch 69/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0261 - val_loss: 0.0031 - val_mae: 0.0287\n",
      "Epoch 70/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0256 - val_loss: 0.0031 - val_mae: 0.0298\n",
      "Epoch 71/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0250 - val_loss: 0.0031 - val_mae: 0.0290\n",
      "Epoch 72/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0255 - val_loss: 0.0030 - val_mae: 0.0282\n",
      "Epoch 73/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0249 - val_loss: 0.0029 - val_mae: 0.0278\n",
      "Epoch 74/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0245 - val_loss: 0.0030 - val_mae: 0.0276\n",
      "Epoch 75/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0245 - val_loss: 0.0029 - val_mae: 0.0276\n",
      "Epoch 76/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0255 - val_loss: 0.0029 - val_mae: 0.0276\n",
      "Epoch 77/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0246 - val_loss: 0.0028 - val_mae: 0.0273\n",
      "Epoch 78/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0254 - val_loss: 0.0029 - val_mae: 0.0278\n",
      "Epoch 79/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0249 - val_loss: 0.0029 - val_mae: 0.0279\n",
      "Epoch 80/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0244 - val_loss: 0.0027 - val_mae: 0.0268\n",
      "Epoch 81/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0253 - val_loss: 0.0028 - val_mae: 0.0272\n",
      "Epoch 82/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0251 - val_loss: 0.0027 - val_mae: 0.0276\n",
      "Epoch 83/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0242 - val_loss: 0.0027 - val_mae: 0.0264\n",
      "Epoch 84/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0241 - val_loss: 0.0027 - val_mae: 0.0263\n",
      "Epoch 85/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0240 - val_loss: 0.0026 - val_mae: 0.0268\n",
      "Epoch 86/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - mae: 0.0240 - val_loss: 0.0027 - val_mae: 0.0272\n",
      "Epoch 87/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0244 - val_loss: 0.0026 - val_mae: 0.0264\n",
      "Epoch 88/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0240 - val_loss: 0.0026 - val_mae: 0.0258\n",
      "Epoch 89/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0241 - val_loss: 0.0025 - val_mae: 0.0259\n",
      "Epoch 90/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0235 - val_loss: 0.0025 - val_mae: 0.0254\n",
      "Epoch 91/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0231 - val_loss: 0.0025 - val_mae: 0.0260\n",
      "Epoch 92/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0242 - val_loss: 0.0025 - val_mae: 0.0260\n",
      "Epoch 93/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0230 - val_loss: 0.0025 - val_mae: 0.0260\n",
      "Epoch 94/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0231 - val_loss: 0.0024 - val_mae: 0.0257\n",
      "Epoch 95/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0231 - val_loss: 0.0024 - val_mae: 0.0267\n",
      "Epoch 96/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0238 - val_loss: 0.0024 - val_mae: 0.0249\n",
      "Epoch 97/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0233 - val_loss: 0.0025 - val_mae: 0.0272\n",
      "Epoch 98/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0247 - val_loss: 0.0024 - val_mae: 0.0254\n",
      "Epoch 99/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0234 - val_loss: 0.0025 - val_mae: 0.0275\n",
      "Epoch 100/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0242 - val_loss: 0.0024 - val_mae: 0.0254\n",
      "Epoch 101/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0247 - val_loss: 0.0024 - val_mae: 0.0259\n",
      "Epoch 102/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0223 - val_loss: 0.0023 - val_mae: 0.0258\n",
      "Epoch 103/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0234 - val_loss: 0.0024 - val_mae: 0.0281\n",
      "Epoch 104/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0236 - val_loss: 0.0023 - val_mae: 0.0262\n",
      "Epoch 105/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0222 - val_loss: 0.0023 - val_mae: 0.0260\n",
      "Epoch 106/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0237 - val_loss: 0.0023 - val_mae: 0.0259\n",
      "Epoch 107/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0226 - val_loss: 0.0022 - val_mae: 0.0244\n",
      "Epoch 108/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0230 - val_loss: 0.0023 - val_mae: 0.0268\n",
      "Epoch 109/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0229 - val_loss: 0.0023 - val_mae: 0.0264\n",
      "Epoch 110/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0223 - val_loss: 0.0022 - val_mae: 0.0251\n",
      "Epoch 111/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 0.0023 - val_mae: 0.0281\n",
      "Epoch 112/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0230 - val_loss: 0.0023 - val_mae: 0.0264\n",
      "Epoch 113/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 0.0022 - val_mae: 0.0267\n",
      "Epoch 114/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 0.0022 - val_mae: 0.0261\n",
      "Epoch 115/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0222 - val_loss: 0.0022 - val_mae: 0.0251\n",
      "Epoch 116/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 0.0023 - val_mae: 0.0282\n",
      "Epoch 117/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0227 - val_loss: 0.0022 - val_mae: 0.0256\n",
      "Epoch 118/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 0.0021 - val_mae: 0.0251\n",
      "Epoch 119/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 0.0021 - val_mae: 0.0259\n",
      "Epoch 120/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0222 - val_loss: 0.0022 - val_mae: 0.0266\n",
      "Epoch 121/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0227 - val_loss: 0.0022 - val_mae: 0.0275\n",
      "Epoch 122/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0232 - val_loss: 0.0021 - val_mae: 0.0260\n",
      "Epoch 123/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0223 - val_loss: 0.0021 - val_mae: 0.0250\n",
      "Epoch 124/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0229 - val_loss: 0.0021 - val_mae: 0.0257\n",
      "Epoch 125/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0225 - val_loss: 0.0021 - val_mae: 0.0257\n",
      "Epoch 126/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0222 - val_loss: 0.0020 - val_mae: 0.0250\n",
      "Epoch 127/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 0.0021 - val_mae: 0.0262\n",
      "Epoch 128/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0222 - val_loss: 0.0020 - val_mae: 0.0254\n",
      "Epoch 129/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 0.0020 - val_mae: 0.0237\n",
      "Epoch 130/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 0.0021 - val_mae: 0.0262\n",
      "Epoch 131/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 0.0020 - val_mae: 0.0258\n",
      "Epoch 132/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0218 - val_loss: 0.0020 - val_mae: 0.0254\n",
      "Epoch 133/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0216 - val_loss: 0.0020 - val_mae: 0.0255\n",
      "Epoch 134/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 0.0019 - val_mae: 0.0240\n",
      "Epoch 135/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 0.0020 - val_mae: 0.0249\n",
      "Epoch 136/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 0.0020 - val_mae: 0.0248\n",
      "Epoch 137/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 0.0019 - val_mae: 0.0245\n",
      "Epoch 138/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0020 - val_mae: 0.0262\n",
      "Epoch 139/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 0.0019 - val_mae: 0.0244\n",
      "Epoch 140/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 0.0020 - val_mae: 0.0263\n",
      "Epoch 141/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 0.0020 - val_mae: 0.0249\n",
      "Epoch 142/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0209 - val_loss: 0.0019 - val_mae: 0.0244\n",
      "Epoch 143/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 0.0019 - val_mae: 0.0237\n",
      "Epoch 144/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 0.0020 - val_mae: 0.0257\n",
      "Epoch 145/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 0.0019 - val_mae: 0.0241\n",
      "Epoch 146/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0019 - val_mae: 0.0244\n",
      "Epoch 147/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 0.0019 - val_mae: 0.0253\n",
      "Epoch 148/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 0.0020 - val_mae: 0.0271\n",
      "Epoch 149/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0219 - val_loss: 0.0020 - val_mae: 0.0265\n",
      "Epoch 150/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0225 - val_loss: 0.0020 - val_mae: 0.0269\n",
      "Epoch 151/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 0.0018 - val_mae: 0.0235\n",
      "Epoch 152/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0219 - val_loss: 0.0018 - val_mae: 0.0241\n",
      "Epoch 153/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0218 - val_loss: 0.0018 - val_mae: 0.0234\n",
      "Epoch 154/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0018 - val_mae: 0.0249\n",
      "Epoch 155/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0247\n",
      "Epoch 156/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 0.0019 - val_mae: 0.0258\n",
      "Epoch 157/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0215 - val_loss: 0.0018 - val_mae: 0.0247\n",
      "Epoch 158/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 0.0018 - val_mae: 0.0239\n",
      "Epoch 159/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0237\n",
      "Epoch 160/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0018 - val_mae: 0.0248\n",
      "Epoch 161/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0209 - val_loss: 0.0017 - val_mae: 0.0244\n",
      "Epoch 162/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0018 - val_mae: 0.0250\n",
      "Epoch 163/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 0.0019 - val_mae: 0.0258\n",
      "Epoch 164/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0018 - val_mae: 0.0241\n",
      "Epoch 165/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 0.0018 - val_mae: 0.0246\n",
      "Epoch 166/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0018 - val_mae: 0.0255\n",
      "Epoch 167/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0216 - val_loss: 0.0017 - val_mae: 0.0240\n",
      "Epoch 168/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 0.0017 - val_mae: 0.0232\n",
      "Epoch 169/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 0.0018 - val_mae: 0.0252\n",
      "Epoch 170/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0242\n",
      "Epoch 171/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0235\n",
      "Epoch 172/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0225\n",
      "Epoch 173/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0247\n",
      "Epoch 174/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0242\n",
      "Epoch 175/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0250\n",
      "Epoch 176/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0249\n",
      "Epoch 177/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 0.0019 - val_mae: 0.0274\n",
      "Epoch 178/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 0.0018 - val_mae: 0.0262\n",
      "Epoch 179/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 0.0017 - val_mae: 0.0235\n",
      "Epoch 180/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 0.0017 - val_mae: 0.0243\n",
      "Epoch 181/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 0.0017 - val_mae: 0.0236\n",
      "Epoch 182/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 0.0018 - val_mae: 0.0250\n",
      "Epoch 183/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 0.0017 - val_mae: 0.0241\n",
      "Epoch 184/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0212 - val_loss: 0.0019 - val_mae: 0.0276\n",
      "Epoch 185/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0218 - val_loss: 0.0016 - val_mae: 0.0234\n",
      "Epoch 186/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0232\n",
      "Epoch 187/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0239\n",
      "Epoch 188/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0232\n",
      "Epoch 189/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0254\n",
      "Epoch 190/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0241\n",
      "Epoch 191/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0198 - val_loss: 0.0017 - val_mae: 0.0251\n",
      "Epoch 192/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 0.0017 - val_mae: 0.0250\n",
      "Epoch 193/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0242\n",
      "Epoch 194/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0232\n",
      "Epoch 195/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0236\n",
      "Epoch 196/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0233\n",
      "Epoch 197/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0243\n",
      "Epoch 198/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0240\n",
      "Epoch 199/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0208 - val_loss: 0.0017 - val_mae: 0.0248\n",
      "Epoch 200/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 0.0016 - val_mae: 0.0225\n",
      "Epoch 201/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 0.0016 - val_mae: 0.0239\n",
      "Epoch 202/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0236\n",
      "Epoch 203/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 0.0015 - val_mae: 0.0230\n",
      "Epoch 204/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 0.0015 - val_mae: 0.0234\n",
      "Epoch 205/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0250\n",
      "Epoch 206/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0237\n",
      "Epoch 207/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 0.0016 - val_mae: 0.0243\n",
      "Epoch 208/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0207 - val_loss: 0.0016 - val_mae: 0.0241\n",
      "Epoch 209/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0246\n",
      "Epoch 210/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 0.0014 - val_mae: 0.0215\n",
      "Epoch 211/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 0.0015 - val_mae: 0.0223\n",
      "Epoch 212/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0233\n",
      "Epoch 213/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0219\n",
      "Epoch 214/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0200 - val_loss: 0.0017 - val_mae: 0.0276\n",
      "Epoch 215/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0215 - val_loss: 0.0016 - val_mae: 0.0255\n",
      "Epoch 216/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0215 - val_loss: 0.0015 - val_mae: 0.0245\n",
      "Epoch 217/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0203 - val_loss: 0.0015 - val_mae: 0.0243\n",
      "Epoch 218/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0208 - val_loss: 0.0015 - val_mae: 0.0238\n",
      "Epoch 219/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0196 - val_loss: 0.0015 - val_mae: 0.0247\n",
      "Epoch 220/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 0.0015 - val_mae: 0.0236\n",
      "Epoch 221/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 0.0014 - val_mae: 0.0230\n",
      "Epoch 222/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0208 - val_loss: 0.0015 - val_mae: 0.0242\n",
      "Epoch 223/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 224/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 0.0014 - val_mae: 0.0221\n",
      "Epoch 225/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0203 - val_loss: 0.0014 - val_mae: 0.0225\n",
      "Epoch 226/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 0.0014 - val_mae: 0.0225\n",
      "Epoch 227/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0193 - val_loss: 0.0015 - val_mae: 0.0247\n",
      "Epoch 228/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0198 - val_loss: 0.0015 - val_mae: 0.0233\n",
      "Epoch 229/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0202 - val_loss: 0.0014 - val_mae: 0.0233\n",
      "Epoch 230/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0246\n",
      "Epoch 231/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 232/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 0.0014 - val_mae: 0.0229\n",
      "Epoch 233/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 0.0014 - val_mae: 0.0236\n",
      "Epoch 234/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0197 - val_loss: 0.0014 - val_mae: 0.0217\n",
      "Epoch 235/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 0.0014 - val_mae: 0.0227\n",
      "Epoch 236/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0203 - val_loss: 0.0013 - val_mae: 0.0220\n",
      "Epoch 237/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0195 - val_loss: 0.0015 - val_mae: 0.0264\n",
      "Epoch 238/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0245\n",
      "Epoch 239/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0206 - val_loss: 0.0015 - val_mae: 0.0235\n",
      "Epoch 240/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0206 - val_loss: 0.0013 - val_mae: 0.0212\n",
      "Epoch 241/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0218\n",
      "Epoch 242/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 0.0014 - val_mae: 0.0235\n",
      "Epoch 243/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 244/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0013 - val_mae: 0.0228\n",
      "Epoch 245/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 0.0013 - val_mae: 0.0225\n",
      "Epoch 246/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0191 - val_loss: 0.0013 - val_mae: 0.0225\n",
      "Epoch 247/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 0.0013 - val_mae: 0.0231\n",
      "Epoch 248/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0012 - val_mae: 0.0206\n",
      "Epoch 249/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0217\n",
      "Epoch 250/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0232\n",
      "Epoch 251/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 0.0013 - val_mae: 0.0215\n",
      "Epoch 252/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 0.0012 - val_mae: 0.0206\n",
      "Epoch 253/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 0.0012 - val_mae: 0.0219\n",
      "Epoch 254/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0013 - val_mae: 0.0232\n",
      "Epoch 255/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0195 - val_loss: 0.0012 - val_mae: 0.0222\n",
      "Epoch 256/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0195 - val_loss: 0.0012 - val_mae: 0.0218\n",
      "Epoch 257/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0193 - val_loss: 0.0013 - val_mae: 0.0227\n",
      "Epoch 258/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 259/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 0.0013 - val_mae: 0.0233\n",
      "Epoch 260/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 0.0013 - val_mae: 0.0226\n",
      "Epoch 261/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0217\n",
      "Epoch 262/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 0.0013 - val_mae: 0.0237\n",
      "Epoch 263/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0013 - val_mae: 0.0232\n",
      "Epoch 264/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 0.0012 - val_mae: 0.0218\n",
      "Epoch 265/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0192 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 266/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0213\n",
      "Epoch 267/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0193 - val_loss: 0.0012 - val_mae: 0.0214\n",
      "Epoch 268/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0213\n",
      "Epoch 269/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 0.0012 - val_mae: 0.0220\n",
      "Epoch 270/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 0.0011 - val_mae: 0.0210\n",
      "Epoch 271/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0203\n",
      "Epoch 272/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 0.0011 - val_mae: 0.0215\n",
      "Epoch 273/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 0.0013 - val_mae: 0.0238\n",
      "Epoch 274/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 275/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0011 - val_mae: 0.0214\n",
      "Epoch 276/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0011 - val_mae: 0.0213\n",
      "Epoch 277/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 278/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0011 - val_mae: 0.0205\n",
      "Epoch 279/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0203\n",
      "Epoch 280/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 281/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 0.0011 - val_mae: 0.0217\n",
      "Epoch 282/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0011 - val_mae: 0.0213\n",
      "Epoch 283/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 284/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 0.0011 - val_mae: 0.0216\n",
      "Epoch 285/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 9.8455e-04 - val_mae: 0.0199\n",
      "Epoch 286/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0189 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 287/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0183 - val_loss: 0.0010 - val_mae: 0.0194\n",
      "Epoch 288/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 0.0011 - val_mae: 0.0204\n",
      "Epoch 289/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0184 - val_loss: 0.0011 - val_mae: 0.0216\n",
      "Epoch 290/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0196 - val_loss: 0.0012 - val_mae: 0.0219\n",
      "Epoch 291/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0184 - val_loss: 0.0010 - val_mae: 0.0207\n",
      "Epoch 292/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 0.0011 - val_mae: 0.0208\n",
      "Epoch 293/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0213\n",
      "Epoch 294/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 0.0010 - val_mae: 0.0203\n",
      "Epoch 295/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0182 - val_loss: 0.0010 - val_mae: 0.0197\n",
      "Epoch 296/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0184 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 297/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0190 - val_loss: 0.0011 - val_mae: 0.0214\n",
      "Epoch 298/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 0.0010 - val_mae: 0.0212\n",
      "Epoch 299/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0185 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 300/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0205 - val_loss: 9.4184e-04 - val_mae: 0.0201\n",
      "Epoch 301/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 302/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 9.4083e-04 - val_mae: 0.0192\n",
      "Epoch 303/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 9.6208e-04 - val_mae: 0.0198\n",
      "Epoch 304/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 305/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 9.0834e-04 - val_mae: 0.0199\n",
      "Epoch 306/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 9.1122e-04 - val_mae: 0.0194\n",
      "Epoch 307/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 9.8441e-04 - val_mae: 0.0204\n",
      "Epoch 308/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 9.5006e-04 - val_mae: 0.0206\n",
      "Epoch 309/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 310/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 9.9500e-04 - val_mae: 0.0197\n",
      "Epoch 311/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0182 - val_loss: 9.3799e-04 - val_mae: 0.0205\n",
      "Epoch 312/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0179 - val_loss: 0.0010 - val_mae: 0.0213\n",
      "Epoch 313/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 0.0010 - val_mae: 0.0204\n",
      "Epoch 314/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 9.1521e-04 - val_mae: 0.0189\n",
      "Epoch 315/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 9.5859e-04 - val_mae: 0.0201\n",
      "Epoch 316/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 9.8212e-04 - val_mae: 0.0204\n",
      "Epoch 317/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 9.4306e-04 - val_mae: 0.0204\n",
      "Epoch 318/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 8.5955e-04 - val_mae: 0.0184\n",
      "Epoch 319/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 9.4329e-04 - val_mae: 0.0196\n",
      "Epoch 320/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 9.6584e-04 - val_mae: 0.0206\n",
      "Epoch 321/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0179 - val_loss: 9.6401e-04 - val_mae: 0.0208\n",
      "Epoch 322/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0176 - val_loss: 8.5221e-04 - val_mae: 0.0189\n",
      "Epoch 323/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 9.1572e-04 - val_mae: 0.0192\n",
      "Epoch 324/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 9.5947e-04 - val_mae: 0.0205\n",
      "Epoch 325/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0176 - val_loss: 9.3108e-04 - val_mae: 0.0201\n",
      "Epoch 326/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0179 - val_loss: 9.3597e-04 - val_mae: 0.0204\n",
      "Epoch 327/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 0.0010 - val_mae: 0.0212\n",
      "Epoch 328/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0179 - val_loss: 9.0911e-04 - val_mae: 0.0199\n",
      "Epoch 329/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 8.8661e-04 - val_mae: 0.0198\n",
      "Epoch 330/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 9.5940e-04 - val_mae: 0.0198\n",
      "Epoch 331/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 9.9340e-04 - val_mae: 0.0222\n",
      "Epoch 332/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0185 - val_loss: 8.3116e-04 - val_mae: 0.0187\n",
      "Epoch 333/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 8.7453e-04 - val_mae: 0.0198\n",
      "Epoch 334/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 8.8028e-04 - val_mae: 0.0196\n",
      "Epoch 335/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 8.8109e-04 - val_mae: 0.0194\n",
      "Epoch 336/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 9.4168e-04 - val_mae: 0.0202\n",
      "Epoch 337/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 8.9452e-04 - val_mae: 0.0201\n",
      "Epoch 338/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 8.8780e-04 - val_mae: 0.0195\n",
      "Epoch 339/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9502e-04 - mae: 0.0170 - val_loss: 8.9118e-04 - val_mae: 0.0194\n",
      "Epoch 340/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0172 - val_loss: 9.1095e-04 - val_mae: 0.0202\n",
      "Epoch 341/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0169 - val_loss: 8.4082e-04 - val_mae: 0.0185\n",
      "Epoch 342/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 8.5883e-04 - val_mae: 0.0193\n",
      "Epoch 343/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 8.4382e-04 - val_mae: 0.0190\n",
      "Epoch 344/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 8.1451e-04 - val_mae: 0.0185\n",
      "Epoch 345/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 8.5329e-04 - val_mae: 0.0195\n",
      "Epoch 346/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 9.1331e-04 - val_mae: 0.0202\n",
      "Epoch 347/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 8.0408e-04 - val_mae: 0.0189\n",
      "Epoch 348/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 8.4102e-04 - val_mae: 0.0196\n",
      "Epoch 349/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 8.3084e-04 - val_mae: 0.0186\n",
      "Epoch 350/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 8.2911e-04 - val_mae: 0.0186\n",
      "Epoch 351/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 8.8882e-04 - val_mae: 0.0200\n",
      "Epoch 352/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 9.1304e-04 - val_mae: 0.0203\n",
      "Epoch 353/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 8.8466e-04 - val_mae: 0.0199\n",
      "Epoch 354/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0176 - val_loss: 8.2555e-04 - val_mae: 0.0193\n",
      "Epoch 355/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0171 - val_loss: 8.1130e-04 - val_mae: 0.0180\n",
      "Epoch 356/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 8.2019e-04 - val_mae: 0.0198\n",
      "Epoch 357/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 9.0284e-04 - val_mae: 0.0198\n",
      "Epoch 358/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0176 - val_loss: 8.5766e-04 - val_mae: 0.0200\n",
      "Epoch 359/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 7.7928e-04 - val_mae: 0.0182\n",
      "Epoch 360/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7850e-04 - mae: 0.0162 - val_loss: 7.9682e-04 - val_mae: 0.0191\n",
      "Epoch 361/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 8.0775e-04 - val_mae: 0.0192\n",
      "Epoch 362/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0174 - val_loss: 8.1223e-04 - val_mae: 0.0194\n",
      "Epoch 363/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9788e-04 - mae: 0.0166 - val_loss: 7.8249e-04 - val_mae: 0.0182\n",
      "Epoch 364/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 8.3920e-04 - val_mae: 0.0196\n",
      "Epoch 365/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 7.2799e-04 - val_mae: 0.0176\n",
      "Epoch 366/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 8.0645e-04 - val_mae: 0.0187\n",
      "Epoch 367/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 7.9951e-04 - val_mae: 0.0196\n",
      "Epoch 368/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mae: 0.0166 - val_loss: 7.5222e-04 - val_mae: 0.0173\n",
      "Epoch 369/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 7.7726e-04 - val_mae: 0.0184\n",
      "Epoch 370/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6279e-04 - mae: 0.0167 - val_loss: 7.4737e-04 - val_mae: 0.0177\n",
      "Epoch 371/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8033e-04 - mae: 0.0162 - val_loss: 7.7453e-04 - val_mae: 0.0182\n",
      "Epoch 372/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7213e-04 - mae: 0.0163 - val_loss: 8.6104e-04 - val_mae: 0.0197\n",
      "Epoch 373/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7118e-04 - mae: 0.0161 - val_loss: 7.6232e-04 - val_mae: 0.0179\n",
      "Epoch 374/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8286e-04 - mae: 0.0162 - val_loss: 8.9975e-04 - val_mae: 0.0199\n",
      "Epoch 375/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8537e-04 - mae: 0.0174 - val_loss: 7.7348e-04 - val_mae: 0.0182\n",
      "Epoch 376/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 7.3673e-04 - val_mae: 0.0175\n",
      "Epoch 377/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9879e-04 - mae: 0.0161 - val_loss: 7.9909e-04 - val_mae: 0.0195\n",
      "Epoch 378/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 6.6808e-04 - val_mae: 0.0168\n",
      "Epoch 379/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2032e-04 - mae: 0.0156 - val_loss: 8.5156e-04 - val_mae: 0.0200\n",
      "Epoch 380/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 7.3335e-04 - val_mae: 0.0180\n",
      "Epoch 381/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7426e-04 - mae: 0.0160 - val_loss: 7.9948e-04 - val_mae: 0.0184\n",
      "Epoch 382/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1265e-04 - mae: 0.0153 - val_loss: 7.2928e-04 - val_mae: 0.0173\n",
      "Epoch 383/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5903e-04 - mae: 0.0157 - val_loss: 7.0633e-04 - val_mae: 0.0176\n",
      "Epoch 384/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3674e-04 - mae: 0.0158 - val_loss: 7.4654e-04 - val_mae: 0.0179\n",
      "Epoch 385/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6369e-04 - mae: 0.0160 - val_loss: 7.2036e-04 - val_mae: 0.0171\n",
      "Epoch 386/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7175e-04 - mae: 0.0167 - val_loss: 8.0086e-04 - val_mae: 0.0193\n",
      "Epoch 387/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3261e-04 - mae: 0.0166 - val_loss: 7.1754e-04 - val_mae: 0.0175\n",
      "Epoch 388/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1563e-04 - mae: 0.0156 - val_loss: 7.1082e-04 - val_mae: 0.0180\n",
      "Epoch 389/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1391e-04 - mae: 0.0156 - val_loss: 6.4494e-04 - val_mae: 0.0163\n",
      "Epoch 390/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3758e-04 - mae: 0.0155 - val_loss: 7.0228e-04 - val_mae: 0.0176\n",
      "Epoch 391/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3170e-04 - mae: 0.0156 - val_loss: 8.1762e-04 - val_mae: 0.0181\n",
      "Epoch 392/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6850e-04 - mae: 0.0159 - val_loss: 7.9450e-04 - val_mae: 0.0187\n",
      "Epoch 393/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7788e-04 - mae: 0.0165 - val_loss: 6.8648e-04 - val_mae: 0.0171\n",
      "Epoch 394/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4930e-04 - mae: 0.0156 - val_loss: 7.0740e-04 - val_mae: 0.0185\n",
      "Epoch 395/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3228e-04 - mae: 0.0157 - val_loss: 7.1963e-04 - val_mae: 0.0175\n",
      "Epoch 396/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6080e-04 - mae: 0.0167 - val_loss: 6.7163e-04 - val_mae: 0.0159\n",
      "Epoch 397/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0369e-04 - mae: 0.0159 - val_loss: 6.9633e-04 - val_mae: 0.0178\n",
      "Epoch 398/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3316e-04 - mae: 0.0157 - val_loss: 6.4771e-04 - val_mae: 0.0165\n",
      "Epoch 399/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5198e-04 - mae: 0.0153 - val_loss: 7.5253e-04 - val_mae: 0.0175\n",
      "Epoch 400/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1307e-04 - mae: 0.0157 - val_loss: 6.4802e-04 - val_mae: 0.0164\n",
      "Epoch 401/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2892e-04 - mae: 0.0159 - val_loss: 6.7586e-04 - val_mae: 0.0170\n",
      "Epoch 402/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2113e-04 - mae: 0.0155 - val_loss: 6.8182e-04 - val_mae: 0.0169\n",
      "Epoch 403/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4618e-04 - mae: 0.0160 - val_loss: 6.9899e-04 - val_mae: 0.0169\n",
      "Epoch 404/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1087e-04 - mae: 0.0150 - val_loss: 6.7595e-04 - val_mae: 0.0165\n",
      "Epoch 405/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8386e-04 - mae: 0.0147 - val_loss: 6.7949e-04 - val_mae: 0.0169\n",
      "Epoch 406/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6552e-04 - mae: 0.0150 - val_loss: 6.8712e-04 - val_mae: 0.0171\n",
      "Epoch 407/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 6.6498e-04 - val_mae: 0.0169\n",
      "Epoch 408/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3077e-04 - mae: 0.0158 - val_loss: 7.0337e-04 - val_mae: 0.0175\n",
      "Epoch 409/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7440e-04 - mae: 0.0149 - val_loss: 6.2037e-04 - val_mae: 0.0156\n",
      "Epoch 410/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2994e-04 - mae: 0.0144 - val_loss: 7.5282e-04 - val_mae: 0.0181\n",
      "Epoch 411/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3513e-04 - mae: 0.0154 - val_loss: 7.1254e-04 - val_mae: 0.0177\n",
      "Epoch 412/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1490e-04 - mae: 0.0153 - val_loss: 7.0182e-04 - val_mae: 0.0168\n",
      "Epoch 413/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4416e-04 - mae: 0.0152 - val_loss: 6.8086e-04 - val_mae: 0.0173\n",
      "Epoch 414/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3309e-04 - mae: 0.0149 - val_loss: 6.2201e-04 - val_mae: 0.0169\n",
      "Epoch 415/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9106e-04 - mae: 0.0157 - val_loss: 6.0768e-04 - val_mae: 0.0162\n",
      "Epoch 416/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0801e-04 - mae: 0.0153 - val_loss: 6.0046e-04 - val_mae: 0.0157\n",
      "Epoch 417/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8966e-04 - mae: 0.0144 - val_loss: 6.0364e-04 - val_mae: 0.0151\n",
      "Epoch 418/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4545e-04 - mae: 0.0153 - val_loss: 7.2730e-04 - val_mae: 0.0184\n",
      "Epoch 419/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9925e-04 - mae: 0.0158 - val_loss: 6.2542e-04 - val_mae: 0.0163\n",
      "Epoch 420/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7990e-04 - mae: 0.0153 - val_loss: 6.2813e-04 - val_mae: 0.0169\n",
      "Epoch 421/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0506e-04 - mae: 0.0158 - val_loss: 6.3188e-04 - val_mae: 0.0163\n",
      "Epoch 422/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8892e-04 - mae: 0.0147 - val_loss: 6.3886e-04 - val_mae: 0.0164\n",
      "Epoch 423/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5096e-04 - mae: 0.0146 - val_loss: 6.5500e-04 - val_mae: 0.0163\n",
      "Epoch 424/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1987e-04 - mae: 0.0153 - val_loss: 6.5607e-04 - val_mae: 0.0171\n",
      "Epoch 425/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3860e-04 - mae: 0.0146 - val_loss: 5.7956e-04 - val_mae: 0.0154\n",
      "Epoch 426/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2563e-04 - mae: 0.0150 - val_loss: 6.3453e-04 - val_mae: 0.0167\n",
      "Epoch 427/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9602e-04 - mae: 0.0153 - val_loss: 5.6978e-04 - val_mae: 0.0158\n",
      "Epoch 428/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0745e-04 - mae: 0.0147 - val_loss: 6.2489e-04 - val_mae: 0.0154\n",
      "Epoch 429/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2871e-04 - mae: 0.0141 - val_loss: 6.3742e-04 - val_mae: 0.0169\n",
      "Epoch 430/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2229e-04 - mae: 0.0153 - val_loss: 5.6466e-04 - val_mae: 0.0150\n",
      "Epoch 431/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3553e-04 - mae: 0.0147 - val_loss: 6.3071e-04 - val_mae: 0.0174\n",
      "Epoch 432/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0595e-04 - mae: 0.0150 - val_loss: 6.3471e-04 - val_mae: 0.0166\n",
      "Epoch 433/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7493e-04 - mae: 0.0157 - val_loss: 6.1875e-04 - val_mae: 0.0164\n",
      "Epoch 434/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6364e-04 - mae: 0.0145 - val_loss: 6.1128e-04 - val_mae: 0.0155\n",
      "Epoch 435/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6475e-04 - mae: 0.0150 - val_loss: 6.7853e-04 - val_mae: 0.0172\n",
      "Epoch 436/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7742e-04 - mae: 0.0160 - val_loss: 6.7594e-04 - val_mae: 0.0180\n",
      "Epoch 437/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7709e-04 - mae: 0.0150 - val_loss: 5.8531e-04 - val_mae: 0.0159\n",
      "Epoch 438/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2967e-04 - mae: 0.0147 - val_loss: 6.3771e-04 - val_mae: 0.0163\n",
      "Epoch 439/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1131e-04 - mae: 0.0154 - val_loss: 6.2323e-04 - val_mae: 0.0157\n",
      "Epoch 440/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6153e-04 - mae: 0.0152 - val_loss: 6.2274e-04 - val_mae: 0.0163\n",
      "Epoch 441/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6278e-04 - mae: 0.0144 - val_loss: 6.7140e-04 - val_mae: 0.0158\n",
      "Epoch 442/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7279e-04 - mae: 0.0151 - val_loss: 6.4639e-04 - val_mae: 0.0174\n",
      "Epoch 443/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5194e-04 - mae: 0.0151 - val_loss: 5.8651e-04 - val_mae: 0.0154\n",
      "Epoch 444/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5503e-04 - mae: 0.0137 - val_loss: 5.5610e-04 - val_mae: 0.0147\n",
      "Epoch 445/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1974e-04 - mae: 0.0141 - val_loss: 5.7829e-04 - val_mae: 0.0156\n",
      "Epoch 446/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1489e-04 - mae: 0.0145 - val_loss: 5.4341e-04 - val_mae: 0.0154\n",
      "Epoch 447/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7822e-04 - mae: 0.0145 - val_loss: 5.8025e-04 - val_mae: 0.0150\n",
      "Epoch 448/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3000e-04 - mae: 0.0140 - val_loss: 6.6664e-04 - val_mae: 0.0178\n",
      "Epoch 449/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1986e-04 - mae: 0.0148 - val_loss: 5.6789e-04 - val_mae: 0.0152\n",
      "Epoch 450/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1999e-04 - mae: 0.0143 - val_loss: 5.5436e-04 - val_mae: 0.0148\n",
      "Epoch 451/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5584e-04 - mae: 0.0142 - val_loss: 5.4979e-04 - val_mae: 0.0148\n",
      "Epoch 452/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3064e-04 - mae: 0.0143 - val_loss: 5.9233e-04 - val_mae: 0.0158\n",
      "Epoch 453/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5706e-04 - mae: 0.0143 - val_loss: 5.9260e-04 - val_mae: 0.0153\n",
      "Epoch 454/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1169e-04 - mae: 0.0146 - val_loss: 6.1468e-04 - val_mae: 0.0161\n",
      "Epoch 455/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4322e-04 - mae: 0.0138 - val_loss: 6.1996e-04 - val_mae: 0.0155\n",
      "Epoch 456/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9782e-04 - mae: 0.0142 - val_loss: 6.3671e-04 - val_mae: 0.0170\n",
      "Epoch 457/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6079e-04 - mae: 0.0149 - val_loss: 5.4520e-04 - val_mae: 0.0157\n",
      "Epoch 458/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5168e-04 - mae: 0.0148 - val_loss: 5.1014e-04 - val_mae: 0.0139\n",
      "Epoch 459/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8608e-04 - mae: 0.0140 - val_loss: 6.0139e-04 - val_mae: 0.0169\n",
      "Epoch 460/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5585e-04 - mae: 0.0150 - val_loss: 5.4619e-04 - val_mae: 0.0146\n",
      "Epoch 461/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1484e-04 - mae: 0.0142 - val_loss: 5.5170e-04 - val_mae: 0.0144\n",
      "Epoch 462/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8542e-04 - mae: 0.0137 - val_loss: 5.9386e-04 - val_mae: 0.0153\n",
      "Epoch 463/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3817e-04 - mae: 0.0136 - val_loss: 5.8673e-04 - val_mae: 0.0158\n",
      "Epoch 464/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3002e-04 - mae: 0.0139 - val_loss: 5.0169e-04 - val_mae: 0.0138\n",
      "Epoch 465/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4462e-04 - mae: 0.0137 - val_loss: 5.2298e-04 - val_mae: 0.0142\n",
      "Epoch 466/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3525e-04 - mae: 0.0136 - val_loss: 5.8431e-04 - val_mae: 0.0148\n",
      "Epoch 467/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9635e-04 - mae: 0.0140 - val_loss: 5.8991e-04 - val_mae: 0.0168\n",
      "Epoch 468/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9584e-04 - mae: 0.0143 - val_loss: 5.9052e-04 - val_mae: 0.0159\n",
      "Epoch 469/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2872e-04 - mae: 0.0146 - val_loss: 5.8242e-04 - val_mae: 0.0161\n",
      "Epoch 470/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6786e-04 - mae: 0.0144 - val_loss: 5.9486e-04 - val_mae: 0.0152\n",
      "Epoch 471/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2039e-04 - mae: 0.0139 - val_loss: 5.4848e-04 - val_mae: 0.0152\n",
      "Epoch 472/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8261e-04 - mae: 0.0134 - val_loss: 5.3496e-04 - val_mae: 0.0143\n",
      "Epoch 473/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9415e-04 - mae: 0.0135 - val_loss: 5.6716e-04 - val_mae: 0.0151\n",
      "Epoch 474/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0966e-04 - mae: 0.0139 - val_loss: 5.6876e-04 - val_mae: 0.0157\n",
      "Epoch 475/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0933e-04 - mae: 0.0138 - val_loss: 5.2361e-04 - val_mae: 0.0141\n",
      "Epoch 476/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8552e-04 - mae: 0.0140 - val_loss: 5.1091e-04 - val_mae: 0.0149\n",
      "Epoch 477/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9975e-04 - mae: 0.0134 - val_loss: 5.5222e-04 - val_mae: 0.0160\n",
      "Epoch 478/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0391e-04 - mae: 0.0141 - val_loss: 5.6560e-04 - val_mae: 0.0156\n",
      "Epoch 479/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7053e-04 - mae: 0.0134 - val_loss: 5.4220e-04 - val_mae: 0.0138\n",
      "Epoch 480/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1165e-04 - mae: 0.0140 - val_loss: 5.6248e-04 - val_mae: 0.0149\n",
      "Epoch 481/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9899e-04 - mae: 0.0139 - val_loss: 5.4726e-04 - val_mae: 0.0147\n",
      "Epoch 482/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6208e-04 - mae: 0.0136 - val_loss: 5.3234e-04 - val_mae: 0.0149\n",
      "Epoch 483/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9937e-04 - mae: 0.0137 - val_loss: 6.0185e-04 - val_mae: 0.0152\n",
      "Epoch 484/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0734e-04 - mae: 0.0145 - val_loss: 5.5630e-04 - val_mae: 0.0149\n",
      "Epoch 485/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9448e-04 - mae: 0.0138 - val_loss: 5.2396e-04 - val_mae: 0.0153\n",
      "Epoch 486/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9645e-04 - mae: 0.0141 - val_loss: 5.9027e-04 - val_mae: 0.0162\n",
      "Epoch 487/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0159e-04 - mae: 0.0136 - val_loss: 5.1975e-04 - val_mae: 0.0141\n",
      "Epoch 488/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5348e-04 - mae: 0.0138 - val_loss: 5.2872e-04 - val_mae: 0.0147\n",
      "Epoch 489/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2067e-04 - mae: 0.0134 - val_loss: 4.8632e-04 - val_mae: 0.0139\n",
      "Epoch 490/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5772e-04 - mae: 0.0131 - val_loss: 5.3136e-04 - val_mae: 0.0150\n",
      "Epoch 491/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1211e-04 - mae: 0.0138 - val_loss: 5.2188e-04 - val_mae: 0.0146\n",
      "Epoch 492/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9164e-04 - mae: 0.0137 - val_loss: 5.1139e-04 - val_mae: 0.0149\n",
      "Epoch 493/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1792e-04 - mae: 0.0133 - val_loss: 5.3720e-04 - val_mae: 0.0141\n",
      "Epoch 494/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5680e-04 - mae: 0.0134 - val_loss: 5.1256e-04 - val_mae: 0.0147\n",
      "Epoch 495/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2466e-04 - mae: 0.0137 - val_loss: 5.2909e-04 - val_mae: 0.0157\n",
      "Epoch 496/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5869e-04 - mae: 0.0138 - val_loss: 5.4912e-04 - val_mae: 0.0155\n",
      "Epoch 497/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8857e-04 - mae: 0.0136 - val_loss: 4.8735e-04 - val_mae: 0.0136\n",
      "Epoch 498/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4718e-04 - mae: 0.0135 - val_loss: 5.7255e-04 - val_mae: 0.0159\n",
      "Epoch 499/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7650e-04 - mae: 0.0133 - val_loss: 5.0822e-04 - val_mae: 0.0142\n",
      "Epoch 500/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5586e-04 - mae: 0.0134 - val_loss: 4.9333e-04 - val_mae: 0.0137\n",
      "Epoch 501/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5669e-04 - mae: 0.0137 - val_loss: 5.9312e-04 - val_mae: 0.0163\n",
      "Epoch 502/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0182e-04 - mae: 0.0131 - val_loss: 4.7246e-04 - val_mae: 0.0138\n",
      "Epoch 503/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0220e-04 - mae: 0.0136 - val_loss: 4.9275e-04 - val_mae: 0.0143\n",
      "Epoch 504/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4343e-04 - mae: 0.0130 - val_loss: 5.0416e-04 - val_mae: 0.0146\n",
      "Epoch 505/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1362e-04 - mae: 0.0133 - val_loss: 4.9034e-04 - val_mae: 0.0144\n",
      "Epoch 506/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3621e-04 - mae: 0.0130 - val_loss: 5.2914e-04 - val_mae: 0.0153\n",
      "Epoch 507/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5733e-04 - mae: 0.0134 - val_loss: 5.3111e-04 - val_mae: 0.0150\n",
      "Epoch 508/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1249e-04 - mae: 0.0135 - val_loss: 4.8323e-04 - val_mae: 0.0139\n",
      "Epoch 509/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6202e-04 - mae: 0.0135 - val_loss: 5.3652e-04 - val_mae: 0.0147\n",
      "Epoch 510/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6531e-04 - mae: 0.0128 - val_loss: 4.6060e-04 - val_mae: 0.0131\n",
      "Epoch 511/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4055e-04 - mae: 0.0132 - val_loss: 5.3627e-04 - val_mae: 0.0159\n",
      "Epoch 512/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0710e-04 - mae: 0.0147 - val_loss: 5.8944e-04 - val_mae: 0.0158\n",
      "Epoch 513/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6452e-04 - mae: 0.0137 - val_loss: 6.1764e-04 - val_mae: 0.0149\n",
      "Epoch 514/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1956e-04 - mae: 0.0146 - val_loss: 5.3123e-04 - val_mae: 0.0153\n",
      "Epoch 515/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6396e-04 - mae: 0.0139 - val_loss: 5.4268e-04 - val_mae: 0.0144\n",
      "Epoch 516/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1597e-04 - mae: 0.0132 - val_loss: 5.0975e-04 - val_mae: 0.0138\n",
      "Epoch 517/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0046e-04 - mae: 0.0128 - val_loss: 5.0956e-04 - val_mae: 0.0142\n",
      "Epoch 518/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1968e-04 - mae: 0.0123 - val_loss: 4.9597e-04 - val_mae: 0.0141\n",
      "Epoch 519/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7058e-04 - mae: 0.0131 - val_loss: 4.5768e-04 - val_mae: 0.0132\n",
      "Epoch 520/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0403e-04 - mae: 0.0128 - val_loss: 4.9299e-04 - val_mae: 0.0144\n",
      "Epoch 521/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6886e-04 - mae: 0.0132 - val_loss: 4.8205e-04 - val_mae: 0.0142\n",
      "Epoch 522/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0552e-04 - mae: 0.0125 - val_loss: 5.0587e-04 - val_mae: 0.0145\n",
      "Epoch 523/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7637e-04 - mae: 0.0133 - val_loss: 5.0011e-04 - val_mae: 0.0141\n",
      "Epoch 524/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4057e-04 - mae: 0.0131 - val_loss: 4.5484e-04 - val_mae: 0.0134\n",
      "Epoch 525/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2865e-04 - mae: 0.0133 - val_loss: 4.9970e-04 - val_mae: 0.0148\n",
      "Epoch 526/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2586e-04 - mae: 0.0128 - val_loss: 4.4781e-04 - val_mae: 0.0133\n",
      "Epoch 527/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1759e-04 - mae: 0.0132 - val_loss: 4.7423e-04 - val_mae: 0.0133\n",
      "Epoch 528/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2244e-04 - mae: 0.0126 - val_loss: 4.7655e-04 - val_mae: 0.0139\n",
      "Epoch 529/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0233e-04 - mae: 0.0123 - val_loss: 4.3617e-04 - val_mae: 0.0130\n",
      "Epoch 530/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8723e-04 - mae: 0.0125 - val_loss: 4.7840e-04 - val_mae: 0.0141\n",
      "Epoch 531/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2173e-04 - mae: 0.0129 - val_loss: 4.7684e-04 - val_mae: 0.0141\n",
      "Epoch 532/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2821e-04 - mae: 0.0125 - val_loss: 5.1896e-04 - val_mae: 0.0145\n",
      "Epoch 533/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2327e-04 - mae: 0.0126 - val_loss: 5.9259e-04 - val_mae: 0.0146\n",
      "Epoch 534/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4304e-04 - mae: 0.0134 - val_loss: 4.6547e-04 - val_mae: 0.0129\n",
      "Epoch 535/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5331e-04 - mae: 0.0131 - val_loss: 5.0587e-04 - val_mae: 0.0142\n",
      "Epoch 536/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4580e-04 - mae: 0.0125 - val_loss: 4.8981e-04 - val_mae: 0.0150\n",
      "Epoch 537/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8046e-04 - mae: 0.0127 - val_loss: 5.4757e-04 - val_mae: 0.0151\n",
      "Epoch 538/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9175e-04 - mae: 0.0132 - val_loss: 4.9149e-04 - val_mae: 0.0141\n",
      "Epoch 539/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0104e-04 - mae: 0.0135 - val_loss: 4.4005e-04 - val_mae: 0.0131\n",
      "Epoch 540/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2288e-04 - mae: 0.0134 - val_loss: 5.0742e-04 - val_mae: 0.0154\n",
      "Epoch 541/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9902e-04 - mae: 0.0130 - val_loss: 5.0238e-04 - val_mae: 0.0154\n",
      "Epoch 542/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6496e-04 - mae: 0.0132 - val_loss: 4.8487e-04 - val_mae: 0.0141\n",
      "Epoch 543/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1068e-04 - mae: 0.0124 - val_loss: 5.3194e-04 - val_mae: 0.0157\n",
      "Epoch 544/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1282e-04 - mae: 0.0128 - val_loss: 4.3069e-04 - val_mae: 0.0135\n",
      "Epoch 545/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2604e-04 - mae: 0.0131 - val_loss: 4.5906e-04 - val_mae: 0.0132\n",
      "Epoch 546/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0392e-04 - mae: 0.0124 - val_loss: 4.3777e-04 - val_mae: 0.0130\n",
      "Epoch 547/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4617e-04 - mae: 0.0127 - val_loss: 4.5774e-04 - val_mae: 0.0137\n",
      "Epoch 548/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9145e-04 - mae: 0.0124 - val_loss: 4.5020e-04 - val_mae: 0.0137\n",
      "Epoch 549/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0709e-04 - mae: 0.0128 - val_loss: 5.0239e-04 - val_mae: 0.0148\n",
      "Epoch 550/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9974e-04 - mae: 0.0124 - val_loss: 4.5006e-04 - val_mae: 0.0132\n",
      "Epoch 551/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0120e-04 - mae: 0.0124 - val_loss: 5.0437e-04 - val_mae: 0.0139\n",
      "Epoch 552/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3224e-04 - mae: 0.0129 - val_loss: 4.3624e-04 - val_mae: 0.0126\n",
      "Epoch 553/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0085e-04 - mae: 0.0126 - val_loss: 4.7097e-04 - val_mae: 0.0141\n",
      "Epoch 554/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3254e-04 - mae: 0.0125 - val_loss: 4.9146e-04 - val_mae: 0.0147\n",
      "Epoch 555/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8149e-04 - mae: 0.0124 - val_loss: 4.7155e-04 - val_mae: 0.0142\n",
      "Epoch 556/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6050e-04 - mae: 0.0131 - val_loss: 5.2257e-04 - val_mae: 0.0164\n",
      "Epoch 557/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3585e-04 - mae: 0.0143 - val_loss: 4.7229e-04 - val_mae: 0.0140\n",
      "Epoch 558/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4563e-04 - mae: 0.0134 - val_loss: 4.9901e-04 - val_mae: 0.0152\n",
      "Epoch 559/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1871e-04 - mae: 0.0130 - val_loss: 4.8933e-04 - val_mae: 0.0134\n",
      "Epoch 560/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1168e-04 - mae: 0.0127 - val_loss: 4.4592e-04 - val_mae: 0.0140\n",
      "Epoch 561/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8182e-04 - mae: 0.0125 - val_loss: 4.8414e-04 - val_mae: 0.0144\n",
      "Epoch 562/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8727e-04 - mae: 0.0124 - val_loss: 4.5727e-04 - val_mae: 0.0133\n",
      "Epoch 563/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0490e-04 - mae: 0.0122 - val_loss: 4.9028e-04 - val_mae: 0.0140\n",
      "Epoch 564/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7439e-04 - mae: 0.0136 - val_loss: 4.6480e-04 - val_mae: 0.0135\n",
      "Epoch 565/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9933e-04 - mae: 0.0133 - val_loss: 5.3061e-04 - val_mae: 0.0156\n",
      "Epoch 566/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3015e-04 - mae: 0.0125 - val_loss: 4.6126e-04 - val_mae: 0.0140\n",
      "Epoch 567/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9500e-04 - mae: 0.0124 - val_loss: 5.0088e-04 - val_mae: 0.0142\n",
      "Epoch 568/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4235e-04 - mae: 0.0127 - val_loss: 4.7241e-04 - val_mae: 0.0139\n",
      "Epoch 569/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1093e-04 - mae: 0.0124 - val_loss: 4.5071e-04 - val_mae: 0.0143\n",
      "Epoch 570/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4617e-04 - mae: 0.0137 - val_loss: 4.7046e-04 - val_mae: 0.0147\n",
      "Epoch 571/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3231e-04 - mae: 0.0134 - val_loss: 5.1772e-04 - val_mae: 0.0144\n",
      "Epoch 572/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0532e-04 - mae: 0.0126 - val_loss: 4.3539e-04 - val_mae: 0.0125\n",
      "Epoch 573/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3309e-04 - mae: 0.0120 - val_loss: 4.1644e-04 - val_mae: 0.0127\n",
      "Epoch 574/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3808e-04 - mae: 0.0119 - val_loss: 4.6224e-04 - val_mae: 0.0137\n",
      "Epoch 575/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.6334e-04 - mae: 0.0129 - val_loss: 4.7288e-04 - val_mae: 0.0140\n",
      "Epoch 576/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0639e-04 - mae: 0.0126 - val_loss: 4.4968e-04 - val_mae: 0.0137\n",
      "Epoch 577/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4001e-04 - mae: 0.0120 - val_loss: 4.7848e-04 - val_mae: 0.0133\n",
      "Epoch 578/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8464e-04 - mae: 0.0125 - val_loss: 4.6284e-04 - val_mae: 0.0134\n",
      "Epoch 579/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1487e-04 - mae: 0.0123 - val_loss: 4.9100e-04 - val_mae: 0.0137\n",
      "Epoch 580/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5152e-04 - mae: 0.0124 - val_loss: 5.0158e-04 - val_mae: 0.0143\n",
      "Epoch 581/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7923e-04 - mae: 0.0120 - val_loss: 4.7615e-04 - val_mae: 0.0135\n",
      "Epoch 582/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2694e-04 - mae: 0.0126 - val_loss: 4.6513e-04 - val_mae: 0.0138\n",
      "Epoch 583/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8618e-04 - mae: 0.0122 - val_loss: 4.9021e-04 - val_mae: 0.0142\n",
      "Epoch 584/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9078e-04 - mae: 0.0125 - val_loss: 4.8018e-04 - val_mae: 0.0146\n",
      "Epoch 585/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1787e-04 - mae: 0.0123 - val_loss: 4.7934e-04 - val_mae: 0.0134\n",
      "Epoch 586/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3632e-04 - mae: 0.0135 - val_loss: 4.6726e-04 - val_mae: 0.0131\n",
      "Epoch 587/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7841e-04 - mae: 0.0125 - val_loss: 4.9664e-04 - val_mae: 0.0138\n",
      "Epoch 588/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8324e-04 - mae: 0.0123 - val_loss: 5.2309e-04 - val_mae: 0.0142\n",
      "Epoch 589/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6164e-04 - mae: 0.0128 - val_loss: 4.8648e-04 - val_mae: 0.0151\n",
      "Epoch 590/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6412e-04 - mae: 0.0127 - val_loss: 4.4491e-04 - val_mae: 0.0131\n",
      "Epoch 591/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5521e-04 - mae: 0.0123 - val_loss: 4.9396e-04 - val_mae: 0.0150\n",
      "Epoch 592/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9699e-04 - mae: 0.0119 - val_loss: 5.3659e-04 - val_mae: 0.0152\n",
      "Epoch 593/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0637e-04 - mae: 0.0123 - val_loss: 4.6042e-04 - val_mae: 0.0140\n",
      "Epoch 594/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0083e-04 - mae: 0.0122 - val_loss: 4.4138e-04 - val_mae: 0.0136\n",
      "Epoch 595/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8694e-04 - mae: 0.0123 - val_loss: 4.1959e-04 - val_mae: 0.0131\n",
      "Epoch 596/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7839e-04 - mae: 0.0126 - val_loss: 4.4607e-04 - val_mae: 0.0137\n",
      "Epoch 597/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4372e-04 - mae: 0.0120 - val_loss: 4.3737e-04 - val_mae: 0.0125\n",
      "Epoch 598/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4241e-04 - mae: 0.0116 - val_loss: 4.6632e-04 - val_mae: 0.0147\n",
      "Epoch 599/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1995e-04 - mae: 0.0128 - val_loss: 4.5457e-04 - val_mae: 0.0133\n",
      "Epoch 600/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1121e-04 - mae: 0.0125 - val_loss: 4.3939e-04 - val_mae: 0.0134\n",
      "Epoch 601/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4978e-04 - mae: 0.0130 - val_loss: 4.3547e-04 - val_mae: 0.0134\n",
      "Epoch 602/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5071e-04 - mae: 0.0120 - val_loss: 4.4864e-04 - val_mae: 0.0139\n",
      "Epoch 603/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8110e-04 - mae: 0.0122 - val_loss: 4.4746e-04 - val_mae: 0.0128\n",
      "Epoch 604/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6963e-04 - mae: 0.0122 - val_loss: 4.7372e-04 - val_mae: 0.0145\n",
      "Epoch 605/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9334e-04 - mae: 0.0127 - val_loss: 5.1241e-04 - val_mae: 0.0140\n",
      "Epoch 606/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7551e-04 - mae: 0.0123 - val_loss: 4.6079e-04 - val_mae: 0.0132\n",
      "Epoch 607/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7429e-04 - mae: 0.0119 - val_loss: 4.5963e-04 - val_mae: 0.0146\n",
      "Epoch 608/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9287e-04 - mae: 0.0123 - val_loss: 4.6095e-04 - val_mae: 0.0143\n",
      "Epoch 609/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6604e-04 - mae: 0.0122 - val_loss: 4.4648e-04 - val_mae: 0.0135\n",
      "Epoch 610/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3935e-04 - mae: 0.0116 - val_loss: 4.0826e-04 - val_mae: 0.0128\n",
      "Epoch 611/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3593e-04 - mae: 0.0118 - val_loss: 4.4017e-04 - val_mae: 0.0134\n",
      "Epoch 612/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9035e-04 - mae: 0.0118 - val_loss: 4.1279e-04 - val_mae: 0.0128\n",
      "Epoch 613/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7722e-04 - mae: 0.0116 - val_loss: 4.5591e-04 - val_mae: 0.0131\n",
      "Epoch 614/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5549e-04 - mae: 0.0118 - val_loss: 4.9745e-04 - val_mae: 0.0146\n",
      "Epoch 615/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0564e-04 - mae: 0.0131 - val_loss: 4.6619e-04 - val_mae: 0.0137\n",
      "Epoch 616/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4296e-04 - mae: 0.0121 - val_loss: 4.3542e-04 - val_mae: 0.0132\n",
      "Epoch 617/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4899e-04 - mae: 0.0115 - val_loss: 5.3514e-04 - val_mae: 0.0149\n",
      "Epoch 618/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4634e-04 - mae: 0.0120 - val_loss: 5.4280e-04 - val_mae: 0.0156\n",
      "Epoch 619/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8250e-04 - mae: 0.0126 - val_loss: 5.1186e-04 - val_mae: 0.0159\n",
      "Epoch 620/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3525e-04 - mae: 0.0122 - val_loss: 4.4110e-04 - val_mae: 0.0130\n",
      "Epoch 621/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7198e-04 - mae: 0.0129 - val_loss: 4.4216e-04 - val_mae: 0.0140\n",
      "Epoch 622/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4836e-04 - mae: 0.0129 - val_loss: 4.3707e-04 - val_mae: 0.0135\n",
      "Epoch 623/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7975e-04 - mae: 0.0123 - val_loss: 4.3034e-04 - val_mae: 0.0126\n",
      "Epoch 624/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8033e-04 - mae: 0.0127 - val_loss: 4.1489e-04 - val_mae: 0.0133\n",
      "Epoch 625/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8122e-04 - mae: 0.0119 - val_loss: 4.4467e-04 - val_mae: 0.0125\n",
      "Epoch 626/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8938e-04 - mae: 0.0122 - val_loss: 4.3918e-04 - val_mae: 0.0137\n",
      "Epoch 627/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3075e-04 - mae: 0.0120 - val_loss: 4.6452e-04 - val_mae: 0.0145\n",
      "Epoch 628/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9534e-04 - mae: 0.0129 - val_loss: 4.4584e-04 - val_mae: 0.0137\n",
      "Epoch 629/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6935e-04 - mae: 0.0124 - val_loss: 4.9921e-04 - val_mae: 0.0146\n",
      "Epoch 630/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7510e-04 - mae: 0.0123 - val_loss: 4.4726e-04 - val_mae: 0.0131\n",
      "Epoch 631/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6873e-04 - mae: 0.0117 - val_loss: 4.3871e-04 - val_mae: 0.0126\n",
      "Epoch 632/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0068e-04 - mae: 0.0120 - val_loss: 4.9022e-04 - val_mae: 0.0155\n",
      "Epoch 633/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8481e-04 - mae: 0.0123 - val_loss: 4.1734e-04 - val_mae: 0.0126\n",
      "Epoch 634/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6324e-04 - mae: 0.0113 - val_loss: 4.4400e-04 - val_mae: 0.0136\n",
      "Epoch 635/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3032e-04 - mae: 0.0119 - val_loss: 3.9713e-04 - val_mae: 0.0124\n",
      "Epoch 636/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6523e-04 - mae: 0.0118 - val_loss: 4.4754e-04 - val_mae: 0.0137\n",
      "Epoch 637/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0251e-04 - mae: 0.0117 - val_loss: 4.2690e-04 - val_mae: 0.0127\n",
      "Epoch 638/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6657e-04 - mae: 0.0115 - val_loss: 4.1506e-04 - val_mae: 0.0129\n",
      "Epoch 639/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9806e-04 - mae: 0.0115 - val_loss: 4.6553e-04 - val_mae: 0.0148\n",
      "Epoch 640/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9660e-04 - mae: 0.0120 - val_loss: 4.0870e-04 - val_mae: 0.0130\n",
      "Epoch 641/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5099e-04 - mae: 0.0119 - val_loss: 4.1709e-04 - val_mae: 0.0126\n",
      "Epoch 642/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2344e-04 - mae: 0.0139 - val_loss: 4.3087e-04 - val_mae: 0.0135\n",
      "Epoch 643/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6303e-04 - mae: 0.0123 - val_loss: 4.2095e-04 - val_mae: 0.0124\n",
      "Epoch 644/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7247e-04 - mae: 0.0127 - val_loss: 4.7528e-04 - val_mae: 0.0149\n",
      "Epoch 645/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8336e-04 - mae: 0.0128 - val_loss: 4.3756e-04 - val_mae: 0.0136\n",
      "Epoch 646/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3784e-04 - mae: 0.0118 - val_loss: 4.7652e-04 - val_mae: 0.0149\n",
      "Epoch 647/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8338e-04 - mae: 0.0123 - val_loss: 4.2203e-04 - val_mae: 0.0126\n",
      "Epoch 648/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2391e-04 - mae: 0.0116 - val_loss: 4.5977e-04 - val_mae: 0.0140\n",
      "Epoch 649/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0419e-04 - mae: 0.0118 - val_loss: 4.6091e-04 - val_mae: 0.0127\n",
      "Epoch 650/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3632e-04 - mae: 0.0121 - val_loss: 4.5649e-04 - val_mae: 0.0142\n",
      "Epoch 651/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4183e-04 - mae: 0.0121 - val_loss: 4.1511e-04 - val_mae: 0.0136\n",
      "Epoch 652/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0526e-04 - mae: 0.0123 - val_loss: 4.4316e-04 - val_mae: 0.0134\n",
      "Epoch 653/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2112e-04 - mae: 0.0125 - val_loss: 4.3550e-04 - val_mae: 0.0137\n",
      "Epoch 654/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4003e-04 - mae: 0.0117 - val_loss: 4.1811e-04 - val_mae: 0.0134\n",
      "Epoch 655/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4584e-04 - mae: 0.0123 - val_loss: 4.8508e-04 - val_mae: 0.0151\n",
      "Epoch 656/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3947e-04 - mae: 0.0120 - val_loss: 4.4660e-04 - val_mae: 0.0130\n",
      "Epoch 657/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2518e-04 - mae: 0.0116 - val_loss: 4.9324e-04 - val_mae: 0.0142\n",
      "Epoch 658/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9141e-04 - mae: 0.0119 - val_loss: 4.5191e-04 - val_mae: 0.0132\n",
      "Epoch 659/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6546e-04 - mae: 0.0119 - val_loss: 5.3079e-04 - val_mae: 0.0161\n",
      "Epoch 660/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8086e-04 - mae: 0.0120 - val_loss: 4.5798e-04 - val_mae: 0.0137\n",
      "Epoch 661/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4833e-04 - mae: 0.0114 - val_loss: 4.4040e-04 - val_mae: 0.0135\n",
      "Epoch 662/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1777e-04 - mae: 0.0112 - val_loss: 4.0206e-04 - val_mae: 0.0122\n",
      "Epoch 663/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4556e-04 - mae: 0.0116 - val_loss: 5.0491e-04 - val_mae: 0.0143\n",
      "Epoch 664/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5233e-04 - mae: 0.0115 - val_loss: 4.5575e-04 - val_mae: 0.0143\n",
      "Epoch 665/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7277e-04 - mae: 0.0116 - val_loss: 4.6688e-04 - val_mae: 0.0140\n",
      "Epoch 666/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4463e-04 - mae: 0.0117 - val_loss: 4.0818e-04 - val_mae: 0.0127\n",
      "Epoch 667/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1545e-04 - mae: 0.0116 - val_loss: 4.0033e-04 - val_mae: 0.0128\n",
      "Epoch 668/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6347e-04 - mae: 0.0118 - val_loss: 5.1918e-04 - val_mae: 0.0147\n",
      "Epoch 669/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3865e-04 - mae: 0.0126 - val_loss: 4.1878e-04 - val_mae: 0.0130\n",
      "Epoch 670/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0433e-04 - mae: 0.0113 - val_loss: 4.2893e-04 - val_mae: 0.0129\n",
      "Epoch 671/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9849e-04 - mae: 0.0117 - val_loss: 4.1228e-04 - val_mae: 0.0126\n",
      "Epoch 672/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7064e-04 - mae: 0.0110 - val_loss: 4.3066e-04 - val_mae: 0.0133\n",
      "Epoch 673/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0564e-04 - mae: 0.0112 - val_loss: 5.0261e-04 - val_mae: 0.0137\n",
      "Epoch 674/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4027e-04 - mae: 0.0115 - val_loss: 5.1673e-04 - val_mae: 0.0145\n",
      "Epoch 675/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1905e-04 - mae: 0.0122 - val_loss: 3.9423e-04 - val_mae: 0.0122\n",
      "Epoch 676/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0398e-04 - mae: 0.0115 - val_loss: 4.2820e-04 - val_mae: 0.0134\n",
      "Epoch 677/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6842e-04 - mae: 0.0116 - val_loss: 4.3549e-04 - val_mae: 0.0135\n",
      "Epoch 678/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5308e-04 - mae: 0.0126 - val_loss: 3.9249e-04 - val_mae: 0.0128\n",
      "Epoch 679/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6135e-04 - mae: 0.0119 - val_loss: 4.9925e-04 - val_mae: 0.0152\n",
      "Epoch 680/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6772e-04 - mae: 0.0119 - val_loss: 4.3225e-04 - val_mae: 0.0140\n",
      "Epoch 681/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2730e-04 - mae: 0.0113 - val_loss: 4.6898e-04 - val_mae: 0.0144\n",
      "Epoch 682/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7790e-04 - mae: 0.0116 - val_loss: 5.4654e-04 - val_mae: 0.0143\n",
      "Epoch 683/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8957e-04 - mae: 0.0125 - val_loss: 4.9958e-04 - val_mae: 0.0152\n",
      "Epoch 684/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2134e-04 - mae: 0.0120 - val_loss: 4.7566e-04 - val_mae: 0.0136\n",
      "Epoch 685/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6931e-04 - mae: 0.0123 - val_loss: 4.6264e-04 - val_mae: 0.0141\n",
      "Epoch 686/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1885e-04 - mae: 0.0122 - val_loss: 5.0567e-04 - val_mae: 0.0154\n",
      "Epoch 687/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4593e-04 - mae: 0.0123 - val_loss: 4.3676e-04 - val_mae: 0.0142\n",
      "Epoch 688/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3463e-04 - mae: 0.0121 - val_loss: 4.4073e-04 - val_mae: 0.0134\n",
      "Epoch 689/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5263e-04 - mae: 0.0122 - val_loss: 4.2911e-04 - val_mae: 0.0127\n",
      "Epoch 690/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0137e-04 - mae: 0.0108 - val_loss: 4.3109e-04 - val_mae: 0.0130\n",
      "Epoch 691/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4601e-04 - mae: 0.0110 - val_loss: 4.5632e-04 - val_mae: 0.0130\n",
      "Epoch 692/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3335e-04 - mae: 0.0112 - val_loss: 3.9650e-04 - val_mae: 0.0123\n",
      "Epoch 693/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8642e-04 - mae: 0.0116 - val_loss: 4.1544e-04 - val_mae: 0.0128\n",
      "Epoch 694/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5748e-04 - mae: 0.0115 - val_loss: 4.1613e-04 - val_mae: 0.0130\n",
      "Epoch 695/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0663e-04 - mae: 0.0120 - val_loss: 4.4029e-04 - val_mae: 0.0141\n",
      "Epoch 696/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1874e-04 - mae: 0.0132 - val_loss: 4.5416e-04 - val_mae: 0.0145\n",
      "Epoch 697/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7942e-04 - mae: 0.0128 - val_loss: 4.0770e-04 - val_mae: 0.0129\n",
      "Epoch 698/800\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8724e-04 - mae: 0.0114 - val_loss: 4.4991e-04 - val_mae: 0.0140\n",
      "Epoch 699/800\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.2539e-04 - mae: 0.0112"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=800, batch_size=256, validation_split=0.2)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2732881e-ba1b-4e17-b9bc-8e02e93ad42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"trained_model_ChillerANN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494fb475-b668-439c-841c-f8271ba42a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAH/CAYAAABpfcWfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdRklEQVR4nO3df2zX9Z3A8Vcp9lvNbGXHUX5cHac75zYnOJCuOmJceiPRsOOPyzhdgCNOz40zjuZugj/onBvlnBqSiSMyPZfcPNgZ9ZZB6rneyOLkQgY0cSdqHDq4Za1wO1qGWyvt5/5Y7NYBjm9t4UV5PJLvH337/nw/7+873Z79fH/wrSiKoggA4JQbd6oXAAD8ligDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASZUf5hz/8YcyfPz+mTp0aFRUV8fTTT//RY7Zu3Rof/ehHo1Qqxfvf//547LHHhrFUABjbyo7y4cOHY8aMGbFu3boTmv/aa6/FtddeG1dffXV0dHTEF77whfjsZz8bzzzzTNmLBYCxrOLdfCFFRUVFPPXUU7FgwYLjzrntttti8+bN8ZOf/GRw7G/+5m/i4MGD0dbWNtxTA8CYM360T7Bt27ZoamoaMjZv3rz4whe+cNxjent7o7e3d/DngYGB+OUvfxl/8id/EhUVFaO1VAA4IUVRxKFDh2Lq1KkxbtzIvT1r1KPc2dkZdXV1Q8bq6uqip6cnfv3rX8fZZ5991DGtra1x9913j/bSAOBd2bdvX/zZn/3ZiN3fqEd5OFauXBnNzc2DP3d3d8f5558f+/bti5qamlO4MgCI6Onpifr6+jj33HNH9H5HPcqTJ0+Orq6uIWNdXV1RU1NzzKvkiIhSqRSlUumo8ZqaGlEGII2Rfkl11D+n3NjYGO3t7UPGnn322WhsbBztUwPAaaXsKP/qV7+Kjo6O6OjoiIjffuSpo6Mj9u7dGxG/fep58eLFg/Nvvvnm2LNnT3zxi1+Ml156KR566KH4zne+E8uXLx+ZRwAAY0TZUf7xj38cl112WVx22WUREdHc3ByXXXZZrFq1KiIifvGLXwwGOiLiz//8z2Pz5s3x7LPPxowZM+L++++Pb37zmzFv3rwReggAMDa8q88pnyw9PT1RW1sb3d3dXlMG4JQbrS75t68BIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASCJYUV53bp1MX369Kiuro6GhobYvn37O85fu3ZtfOADH4izzz476uvrY/ny5fGb3/xmWAsGgLGq7Chv2rQpmpubo6WlJXbu3BkzZsyIefPmxRtvvHHM+Y8//nisWLEiWlpaYvfu3fHII4/Epk2b4vbbb3/XiweAsaTsKD/wwANx4403xtKlS+NDH/pQrF+/Ps4555x49NFHjzn/+eefjyuvvDKuv/76mD59enzyk5+M66677o9eXQPAmaasKPf19cWOHTuiqanpd3cwblw0NTXFtm3bjnnMFVdcETt27BiM8J49e2LLli1xzTXXvItlA8DYM76cyQcOHIj+/v6oq6sbMl5XVxcvvfTSMY+5/vrr48CBA/Hxj388iqKII0eOxM033/yOT1/39vZGb2/v4M89PT3lLBMATkuj/u7rrVu3xurVq+Ohhx6KnTt3xpNPPhmbN2+Oe+6557jHtLa2Rm1t7eCtvr5+tJcJAKdcRVEUxYlO7uvri3POOSeeeOKJWLBgweD4kiVL4uDBg/Hv//7vRx0zd+7c+NjHPhZf+9rXBsf+5V/+JW666ab41a9+FePGHf13wbGulOvr66O7uztqampOdLkAMCp6enqitrZ2xLtU1pVyVVVVzJo1K9rb2wfHBgYGor29PRobG495zJtvvnlUeCsrKyMi4nh/D5RKpaipqRlyA4CxrqzXlCMimpubY8mSJTF79uyYM2dOrF27Ng4fPhxLly6NiIjFixfHtGnTorW1NSIi5s+fHw888EBcdtll0dDQEK+++mrcddddMX/+/ME4AwDDiPLChQtj//79sWrVqujs7IyZM2dGW1vb4Ju/9u7dO+TK+M4774yKioq488474+c//3n86Z/+acyfPz+++tWvjtyjAIAxoKzXlE+V0XruHgCGI8VrygDA6BFlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIYlhRXrduXUyfPj2qq6ujoaEhtm/f/o7zDx48GMuWLYspU6ZEqVSKiy66KLZs2TKsBQPAWDW+3AM2bdoUzc3NsX79+mhoaIi1a9fGvHnz4uWXX45JkyYdNb+vry/+8i//MiZNmhRPPPFETJs2LX72s5/FeeedNxLrB4Axo6IoiqKcAxoaGuLyyy+PBx98MCIiBgYGor6+Pm655ZZYsWLFUfPXr18fX/va1+Kll16Ks846a1iL7Onpidra2uju7o6ampph3QcAjJTR6lJZT1/39fXFjh07oqmp6Xd3MG5cNDU1xbZt2455zHe/+91obGyMZcuWRV1dXVxyySWxevXq6O/vP+55ent7o6enZ8gNAMa6sqJ84MCB6O/vj7q6uiHjdXV10dnZecxj9uzZE0888UT09/fHli1b4q677or7778/vvKVrxz3PK2trVFbWzt4q6+vL2eZAHBaGvV3Xw8MDMSkSZPi4YcfjlmzZsXChQvjjjvuiPXr1x/3mJUrV0Z3d/fgbd++faO9TAA45cp6o9fEiROjsrIyurq6hox3dXXF5MmTj3nMlClT4qyzzorKysrBsQ9+8IPR2dkZfX19UVVVddQxpVIpSqVSOUsDgNNeWVfKVVVVMWvWrGhvbx8cGxgYiPb29mhsbDzmMVdeeWW8+uqrMTAwMDj2yiuvxJQpU44ZZAA4U5X99HVzc3Ns2LAhvvWtb8Xu3bvjc5/7XBw+fDiWLl0aERGLFy+OlStXDs7/3Oc+F7/85S/j1ltvjVdeeSU2b94cq1evjmXLlo3cowCAMaDszykvXLgw9u/fH6tWrYrOzs6YOXNmtLW1Db75a+/evTFu3O9aX19fH88880wsX748Lr300pg2bVrceuutcdttt43cowCAMaDszymfCj6nDEAmKT6nDACMHlEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIIlhRXndunUxffr0qK6ujoaGhti+ffsJHbdx48aoqKiIBQsWDOe0ADCmlR3lTZs2RXNzc7S0tMTOnTtjxowZMW/evHjjjTfe8bjXX389/uEf/iHmzp077MUCwFhWdpQfeOCBuPHGG2Pp0qXxoQ99KNavXx/nnHNOPProo8c9pr+/Pz7zmc/E3XffHRdccMG7WjAAjFVlRbmvry927NgRTU1Nv7uDceOiqakptm3bdtzjvvzlL8ekSZPihhtuOKHz9Pb2Rk9Pz5AbAIx1ZUX5wIED0d/fH3V1dUPG6+rqorOz85jHPPfcc/HII4/Ehg0bTvg8ra2tUVtbO3irr68vZ5kAcFoa1XdfHzp0KBYtWhQbNmyIiRMnnvBxK1eujO7u7sHbvn37RnGVAJDD+HImT5w4MSorK6Orq2vIeFdXV0yePPmo+T/96U/j9ddfj/nz5w+ODQwM/PbE48fHyy+/HBdeeOFRx5VKpSiVSuUsDQBOe2VdKVdVVcWsWbOivb19cGxgYCDa29ujsbHxqPkXX3xxvPDCC9HR0TF4+9SnPhVXX311dHR0eFoaAH5PWVfKERHNzc2xZMmSmD17dsyZMyfWrl0bhw8fjqVLl0ZExOLFi2PatGnR2toa1dXVcckllww5/rzzzouIOGocAM50ZUd54cKFsX///li1alV0dnbGzJkzo62tbfDNX3v37o1x4/xDYQBQroqiKIpTvYg/pqenJ2pra6O7uztqampO9XIAOMONVpdc0gJAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJDCvK69ati+nTp0d1dXU0NDTE9u3bjzt3w4YNMXfu3JgwYUJMmDAhmpqa3nE+AJypyo7ypk2borm5OVpaWmLnzp0xY8aMmDdvXrzxxhvHnL9169a47rrr4gc/+EFs27Yt6uvr45Of/GT8/Oc/f9eLB4CxpKIoiqKcAxoaGuLyyy+PBx98MCIiBgYGor6+Pm655ZZYsWLFHz2+v78/JkyYEA8++GAsXrz4hM7Z09MTtbW10d3dHTU1NeUsFwBG3Gh1qawr5b6+vtixY0c0NTX97g7GjYumpqbYtm3bCd3Hm2++GW+99Va8973vPe6c3t7e6OnpGXIDgLGurCgfOHAg+vv7o66ubsh4XV1ddHZ2ntB93HbbbTF16tQhYf9Dra2tUVtbO3irr68vZ5kAcFo6qe++XrNmTWzcuDGeeuqpqK6uPu68lStXRnd39+Bt3759J3GVAHBqjC9n8sSJE6OysjK6urqGjHd1dcXkyZPf8dj77rsv1qxZE9///vfj0ksvfce5pVIpSqVSOUsDgNNeWVfKVVVVMWvWrGhvbx8cGxgYiPb29mhsbDzucffee2/cc8890dbWFrNnzx7+agFgDCvrSjkiorm5OZYsWRKzZ8+OOXPmxNq1a+Pw4cOxdOnSiIhYvHhxTJs2LVpbWyMi4p/+6Z9i1apV8fjjj8f06dMHX3t+z3veE+95z3tG8KEAwOmt7CgvXLgw9u/fH6tWrYrOzs6YOXNmtLW1Db75a+/evTFu3O8uwL/xjW9EX19f/PVf//WQ+2lpaYkvfelL7271ADCGlP055VPB55QByCTF55QBgNEjygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkMawor1u3LqZPnx7V1dXR0NAQ27dvf8f5//Zv/xYXX3xxVFdXx0c+8pHYsmXLsBYLAGNZ2VHetGlTNDc3R0tLS+zcuTNmzJgR8+bNizfeeOOY859//vm47rrr4oYbbohdu3bFggULYsGCBfGTn/zkXS8eAMaSiqIoinIOaGhoiMsvvzwefPDBiIgYGBiI+vr6uOWWW2LFihVHzV+4cGEcPnw4vve97w2OfexjH4uZM2fG+vXrT+icPT09UVtbG93d3VFTU1POcgFgxI1Wl8aXM7mvry927NgRK1euHBwbN25cNDU1xbZt2455zLZt26K5uXnI2Lx58+Lpp58+7nl6e3ujt7d38Ofu7u6I+O0mAMCp9naPyryu/aPKivKBAweiv78/6urqhozX1dXFSy+9dMxjOjs7jzm/s7PzuOdpbW2Nu++++6jx+vr6cpYLAKPqf//3f6O2tnbE7q+sKJ8sK1euHHJ1ffDgwXjf+94Xe/fuHdEHf6bq6emJ+vr62Ldvn5cDRog9HVn2c+TZ05HV3d0d559/frz3ve8d0fstK8oTJ06MysrK6OrqGjLe1dUVkydPPuYxkydPLmt+RESpVIpSqXTUeG1trV+mEVRTU2M/R5g9HVn2c+TZ05E1btzIfrK4rHurqqqKWbNmRXt7++DYwMBAtLe3R2Nj4zGPaWxsHDI/IuLZZ5897nwAOFOV/fR1c3NzLFmyJGbPnh1z5syJtWvXxuHDh2Pp0qUREbF48eKYNm1atLa2RkTErbfeGldddVXcf//9ce2118bGjRvjxz/+cTz88MMj+0gA4DRXdpQXLlwY+/fvj1WrVkVnZ2fMnDkz2traBt/MtXfv3iGX81dccUU8/vjjceedd8btt98ef/EXfxFPP/10XHLJJSd8zlKpFC0tLcd8Spvy2c+RZ09Hlv0cefZ0ZI3Wfpb9OWUAYHT4t68BIAlRBoAkRBkAkhBlAEgiTZR9HeTIKmc/N2zYEHPnzo0JEybEhAkToqmp6Y/u/5mo3N/Rt23cuDEqKipiwYIFo7vA00y5+3nw4MFYtmxZTJkyJUqlUlx00UX+d/8Hyt3TtWvXxgc+8IE4++yzo76+PpYvXx6/+c1vTtJqc/vhD38Y8+fPj6lTp0ZFRcU7fl/D27Zu3Rof/ehHo1Qqxfvf//547LHHyj9xkcDGjRuLqqqq4tFHHy3++7//u7jxxhuL8847r+jq6jrm/B/96EdFZWVlce+99xYvvvhiceeddxZnnXVW8cILL5zkledU7n5ef/31xbp164pdu3YVu3fvLv72b/+2qK2tLf7nf/7nJK88r3L39G2vvfZaMW3atGLu3LnFX/3VX52cxZ4Gyt3P3t7eYvbs2cU111xTPPfcc8Vrr71WbN26tejo6DjJK8+r3D399re/XZRKpeLb3/528dprrxXPPPNMMWXKlGL58uUneeU5bdmypbjjjjuKJ598soiI4qmnnnrH+Xv27CnOOeecorm5uXjxxReLr3/960VlZWXR1tZW1nlTRHnOnDnFsmXLBn/u7+8vpk6dWrS2th5z/qc//eni2muvHTLW0NBQ/N3f/d2orvN0Ue5+/qEjR44U5557bvGtb31rtJZ42hnOnh45cqS44oorim9+85vFkiVLRPn3lLuf3/jGN4oLLrig6OvrO1lLPO2Uu6fLli0rPvGJTwwZa25uLq688spRXefp6ESi/MUvfrH48Ic/PGRs4cKFxbx588o61yl/+vrtr4NsamoaHDuRr4P8/fkRv/06yOPNP5MMZz//0JtvvhlvvfXWiP9D66er4e7pl7/85Zg0aVLccMMNJ2OZp43h7Od3v/vdaGxsjGXLlkVdXV1ccsklsXr16ujv7z9Zy05tOHt6xRVXxI4dOwaf4t6zZ09s2bIlrrnmmpOy5rFmpLp0yr8l6mR9HeSZYjj7+Yduu+22mDp16lG/YGeq4ezpc889F4888kh0dHSchBWeXoazn3v27In//M//jM985jOxZcuWePXVV+Pzn/98vPXWW9HS0nIylp3acPb0+uuvjwMHDsTHP/7xKIoijhw5EjfffHPcfvvtJ2PJY87xutTT0xO//vWv4+yzzz6h+znlV8rksmbNmti4cWM89dRTUV1dfaqXc1o6dOhQLFq0KDZs2BATJ0481csZEwYGBmLSpEnx8MMPx6xZs2LhwoVxxx13xPr160/10k5bW7dujdWrV8dDDz0UO3fujCeffDI2b94c99xzz6le2hntlF8pn6yvgzxTDGc/33bffffFmjVr4vvf/35ceumlo7nM00q5e/rTn/40Xn/99Zg/f/7g2MDAQEREjB8/Pl5++eW48MILR3fRiQ3nd3TKlClx1llnRWVl5eDYBz/4wejs7Iy+vr6oqqoa1TVnN5w9veuuu2LRokXx2c9+NiIiPvKRj8Thw4fjpptuijvuuGPEv5JwrDtel2pqak74KjkiwZWyr4McWcPZz4iIe++9N+65555oa2uL2bNnn4ylnjbK3dOLL744Xnjhhejo6Bi8fepTn4qrr746Ojo6or6+/mQuP53h/I5eeeWV8eqrrw7+cRMR8corr8SUKVPO+CBHDG9P33zzzaPC+/YfPYWvRCjbiHWpvPegjY6NGzcWpVKpeOyxx4oXX3yxuOmmm4rzzjuv6OzsLIqiKBYtWlSsWLFicP6PfvSjYvz48cV9991X7N69u2hpafGRqN9T7n6uWbOmqKqqKp544oniF7/4xeDt0KFDp+ohpFPunv4h774eqtz93Lt3b3HuuecWf//3f1+8/PLLxfe+971i0qRJxVe+8pVT9RDSKXdPW1painPPPbf413/912LPnj3Ff/zHfxQXXnhh8elPf/pUPYRUDh06VOzatavYtWtXERHFAw88UOzatav42c9+VhRFUaxYsaJYtGjR4Py3PxL1j//4j8Xu3buLdevWnb4fiSqKovj6179enH/++UVVVVUxZ86c4r/+678G/9tVV11VLFmyZMj873znO8VFF11UVFVVFR/+8IeLzZs3n+QV51bOfr7vfe8rIuKoW0tLy8lfeGLl/o7+PlE+Wrn7+fzzzxcNDQ1FqVQqLrjgguKrX/1qceTIkZO86tzK2dO33nqr+NKXvlRceOGFRXV1dVFfX198/vOfL/7v//7v5C88oR/84AfH/P/Ft/dwyZIlxVVXXXXUMTNnziyqqqqKCy64oPjnf/7nss/rqxsBIIlT/poyAPBbogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkMT/AwbAMwFP3iC4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation mean absolute error values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Model Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c69943-2b68-40ac-8139-77947f9573a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('trained_model_ChillerANN.h5')\n",
    "\n",
    "# Load the model (if needed)\n",
    "loaded_model = tf.keras.models.load_model('trained_model_ChillerANN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd42b66-d437-4dd8-8bd6-768306704145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions and actual values to DataFrames for easier manipulation\n",
    "predictions_df = pd.DataFrame(scaler_y.inverse_transform(y_pred), columns=outputs)\n",
    "actuals_df = pd.DataFrame(scaler_y.inverse_transform(y_test), columns=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c20818-3118-48c4-bafc-2a88174708dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def calculate_metrics(actuals, predictions):\n",
    "    metrics = {}\n",
    "    for output in actuals.columns:\n",
    "        actual_values = actuals[output]\n",
    "        predicted_values = predictions[output]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(actual_values, predicted_values)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mean_actual = np.mean(actual_values)\n",
    "        \n",
    "        # CVRMSE (Coefficient of Variation of RMSE)\n",
    "        cvrmse = (rmse / mean_actual) * 100\n",
    "        \n",
    "        # NMBE (Normalized Mean Bias Error)\n",
    "        nmbe = (np.mean(predicted_values - actual_values) / mean_actual) * 100\n",
    "        \n",
    "        # R2 (Coefficient of Determination)\n",
    "        r2 = r2_score(actual_values, predicted_values)\n",
    "        \n",
    "        metrics[output] = {'CVRMSE': cvrmse, 'NMBE': nmbe, 'R2': r2}\n",
    "    return metrics\n",
    "\n",
    "def plot_actual_vs_predicted(actuals, predictions, output_names):\n",
    "    metrics = calculate_metrics(actuals, predictions)\n",
    "    \n",
    "    num_outputs = len(output_names)\n",
    "    plt.figure(figsize=(15, num_outputs * 5))\n",
    "    \n",
    "    for i, output in enumerate(output_names):\n",
    "        plt.subplot(num_outputs, 1, i + 1)\n",
    "        plt.plot(actuals.index, actuals[output], label='Actual', color='blue', linestyle='--')\n",
    "        plt.plot(predictions.index, predictions[output], label='Predicted', color='red', linestyle='-')\n",
    "        \n",
    "        # Retrieve metrics for current output\n",
    "        cvrmse = metrics[output]['CVRMSE']\n",
    "        nmbe = metrics[output]['NMBE']\n",
    "        r2 = metrics[output]['R2']\n",
    "        \n",
    "        # Print metrics on plot\n",
    "        plt.title(f'Actual vs. Predicted for {output}')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel(output)\n",
    "        plt.legend()\n",
    "        plt.text(0.05, 0.95, f'CVRMSE: {cvrmse:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n",
    "        plt.text(0.05, 0.90, f'NMBE: {nmbe:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n",
    "        plt.text(0.05, 0.85, f'R2: {r2:.2f}', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the updated plotting function\n",
    "plot_actual_vs_predicted(actuals_df, predictions_df, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b357d1f-c16d-4e6a-ab4e-6a6819784f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1s2xo4nw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\tanma\\anaconda3\\envs\\pysparkenv\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "prediction = model.predict(X_test[0])\n",
    "predictions.append(prediction)\n",
    "for row_idx in range(1, X_test.shape[0]):\n",
    "    \n",
    "    prediction = model.predict(np.concatenate([X_test[row_idx][:4], prediction]).reshape(1, -1))\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc01a1b-5b09-4fac-ac8e-fb6c9643fba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7868757-2625-4920-92e0-18b32a9b13e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysparkenv]",
   "language": "python",
   "name": "conda-env-pysparkenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
